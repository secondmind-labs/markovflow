{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca1dc5f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Basic classification using the SPEP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c10dc",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "This notebook explains how to use Markovflow to build and optimise a variational GP regression model (VGP) for a time series. Here, we perform binary classification with time as the input.\n",
    "\n",
    "As with GPR, the observations do not have to be regularly spaced. However, they do need to be sequential. We denote the input/output tuples as $(x_i, y_i)_{1 \\leq i \\leq n}$, where $x_i$ is a scalar value and $y_i \\in \\{0, 1\\}$.\n",
    "\n",
    "Our probabilistic model for this data is:\n",
    "$$\n",
    "\\begin{align}\n",
    "f \\sim \\mathcal{GP}(0, k(., .)) \\\\\n",
    "y_i \\sim \\mathcal{B}(\\Phi(f(x_i)))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\Phi$ is a function that maps $f(x_i)$ to $[0, 1]$, the probability that $y_i=1$. In practice, we choose $\\Phi$ to be the standard normal cumulative distribution function (also known as the probit function) which maps to $[0, 1]$.\n",
    "\n",
    "**NOTE:** If you have difficulty running this notebook, consider clearing the output and then restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Turn off warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpflow import default_float\n",
    "from gpflow.ci_utils import ci_niter\n",
    "from gpflow.likelihoods import Bernoulli\n",
    "\n",
    "\n",
    "from markovflow.likelihoods import PEPScalarLikelihood\n",
    "from markovflow.models.sparse_pep import SparsePowerExpectationPropagation\n",
    "from markovflow.kernels import Matern52\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "FLOAT_TYPE = default_float()\n",
    "\n",
    "# uncomment in notebook\n",
    "# try:\n",
    "#     from IPython import get_ipython\n",
    "#     get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# except AttributeError:\n",
    "#     print('Magic function can only be used in IPython environment')\n",
    "#     matplotlib.use('Agg')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b5dd2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Step 1: Generate training data\n",
    "\n",
    "First, let's generate some binary data $X = (x_1, \\dots, x_n)$ and $Y = (y_1, \\dots, y_n)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a0c72",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Generate some observations\n",
    "num_data = 300\n",
    "num_inducing = 30\n",
    "time_points = np.linspace(0 , 1, num_data)\n",
    "F = np.cos(time_points * 20).reshape(-1, 1)\n",
    "observations = (F + np.random.randn(*F.shape) > 0).astype(float)\n",
    "data = (time_points, observations)\n",
    "inducing_points = np.linspace(0 , 1, num_inducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7691c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "matern_kernel = Matern52(lengthscale=.05, variance=1.0)\n",
    "# Because we are multiplying them together, we need to train only one kernel variance parameter\n",
    "\n",
    "kernel = matern_kernel\n",
    "\n",
    "# We see Matern12 has only two dimensions (therefore there is less risk of overparameterising)\n",
    "print(kernel.state_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8383d8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 3: Build and optimise a model\n",
    "\n",
    "This is a classification problem with outputs between `[0,1]`, so we create a variational GP model using a Bernoulli likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e1de0",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "# Create a likelihood object\n",
    "variance = 1.\n",
    "alpha = 1.\n",
    "base_likelihood = Bernoulli()\n",
    "likelihood = PEPScalarLikelihood(base=base_likelihood)\n",
    "spep = SparsePowerExpectationPropagation(kernel=kernel,\n",
    "                                         inducing_points=tf.constant(inducing_points),\n",
    "                                         likelihood=likelihood,\n",
    "                                         learning_rate=.5,\n",
    "                                         alpha=alpha)\n",
    "\n",
    "\n",
    "def plot_model(model):\n",
    "\n",
    "    f_mu, f_var = model.posterior().predict_f(time_points)\n",
    "    f_mu = f_mu.numpy()\n",
    "    f_std = np.sqrt(f_var)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.vlines(inducing_points, ymin=observations.min(), ymax=observations.max(), color='r')\n",
    "    plt.plot(time_points, observations, 'C0x', ms=8, mew=2)\n",
    "    plt.plot(time_points, F, 'C0', ms=8, mew=2)\n",
    "    plt.plot(time_points, f_mu, 'C1', ms=8, mew=2)\n",
    "    plt.fill_between(\n",
    "        time_points,\n",
    "        y1 = (f_mu - 2 * f_std).reshape(-1,),\n",
    "        y2 = (f_mu + 2 * f_std).reshape(-1,),\n",
    "        alpha=.2\n",
    "    )\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "trainable_vars = (spep._kernel.trainable_variables) \\\n",
    "\n",
    "opt_adam = tf.optimizers.Adam(0.01)\n",
    "\n",
    "#@tf.function\n",
    "def adam_step():\n",
    "    opt_adam.minimize(lambda: -spep.energy(data), trainable_vars)\n",
    "\n",
    "#@tf.function\n",
    "def natgrad_step(input_data):\n",
    "    spep.update_sites(input_data)\n",
    "\n",
    "plot_model(spep)\n",
    "\n",
    "\n",
    "input_data = (time_points, observations)\n",
    "\n",
    "batch_size = num_data // 10\n",
    "max_iter = ci_niter(1000)\n",
    "for rep in range(max_iter):\n",
    "    time_points, observations = input_data\n",
    "\n",
    "    indices = np.random.permutation(num_data)[:batch_size]\n",
    "    sub_input_data = (time_points[indices], observations[indices])\n",
    "\n",
    "    natgrad_step(sub_input_data)\n",
    "    #adam_step()\n",
    "    print(rep, -spep.energy(input_data).numpy())\n",
    "\n",
    "    if rep % 10 == 0:\n",
    "        plot_model(spep)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\"",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
