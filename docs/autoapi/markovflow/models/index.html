
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>markovflow.models &#8212; markovflow 0.1.0 documentation</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/pydata-custom.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="markovflow.models.gaussian_process_regression" href="gaussian_process_regression/index.html" />
    <link rel="prev" title="markovflow.likelihoods.mutlistage_likelihood" href="../likelihoods/mutlistage_likelihood/index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../../index.html">
    
      <img src="../../../_static/logo.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../index.html">Markovflow</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../tutorials.html">Tutorials</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">API Reference</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/secondmind-labs/markovflow" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#submodules" class="nav-link">Submodules</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#package-contents" class="nav-link">Package Contents</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.GaussianProcessRegression" class="nav-link">GaussianProcessRegression</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.time_points" class="nav-link">time_points</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.observations" class="nav-link">observations</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.kernel" class="nav-link">kernel</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.mean_function" class="nav-link">mean_function</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.loss" class="nav-link">loss</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.GaussianProcessRegression.log_likelihood" class="nav-link">log_likelihood</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.ImportanceWeightedVI" class="nav-link">ImportanceWeightedVI</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.ImportanceWeightedVI.elbo" class="nav-link">elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.ImportanceWeightedVI.dregs_objective" class="nav-link">dregs_objective</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.MarkovFlowModel" class="nav-link">MarkovFlowModel</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowModel.loss" class="nav-link">loss</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowModel.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowModel.predict_state" class="nav-link">predict_state</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowModel.predict_f" class="nav-link">predict_f</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.MarkovFlowSparseModel" class="nav-link">MarkovFlowSparseModel</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowSparseModel.loss" class="nav-link">loss</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowSparseModel.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowSparseModel.predict_state" class="nav-link">predict_state</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowSparseModel.predict_f" class="nav-link">predict_f</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.MarkovFlowSparseModel.predict_log_density" class="nav-link">predict_log_density</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.PowerExpectationPropagation" class="nav-link">PowerExpectationPropagation</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.local_objective" class="nav-link">local_objective</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.local_objective_gradients" class="nav-link">local_objective_gradients</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.mask_indices" class="nav-link">mask_indices</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.compute_cavity_from_marginals" class="nav-link">compute_cavity_from_marginals</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.compute_cavity" class="nav-link">compute_cavity</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.compute_log_norm" class="nav-link">compute_log_norm</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.update_sites" class="nav-link">update_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.elbo" class="nav-link">elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.energy" class="nav-link">energy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.PowerExpectationPropagation.predict_log_density" class="nav-link">predict_log_density</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.SparsePowerExpectationPropagation" class="nav-link">SparsePowerExpectationPropagation</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.mask_indices" class="nav-link">mask_indices</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.back_project_nats" class="nav-link">back_project_nats</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.local_objective" class="nav-link">local_objective</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.local_objective_gradients" class="nav-link">local_objective_gradients</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.fraction_sites" class="nav-link">fraction_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_posterior_ssm" class="nav-link">compute_posterior_ssm</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.dist_q" class="nav-link">dist_q</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_marginals" class="nav-link">compute_marginals</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.remove_cavity_from_marginals" class="nav-link">remove_cavity_from_marginals</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_cavity_state" class="nav-link">compute_cavity_state</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_cavity" class="nav-link">compute_cavity</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_new_sites" class="nav-link">compute_new_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_log_norm" class="nav-link">compute_log_norm</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_num_data_per_interval" class="nav-link">compute_num_data_per_interval</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.compute_fraction" class="nav-link">compute_fraction</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.update_sites" class="nav-link">update_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.energy" class="nav-link">energy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.loss" class="nav-link">loss</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.dist_p" class="nav-link">dist_p</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.kernel" class="nav-link">kernel</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.classic_elbo" class="nav-link">classic_elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparsePowerExpectationPropagation.predict_log_density" class="nav-link">predict_log_density</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.SparseVariationalGaussianProcess" class="nav-link">SparseVariationalGaussianProcess</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.elbo" class="nav-link">elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.time_points" class="nav-link">time_points</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.kernel" class="nav-link">kernel</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.likelihood" class="nav-link">likelihood</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.mean_function" class="nav-link">mean_function</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.dist_p" class="nav-link">dist_p</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.dist_q" class="nav-link">dist_q</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.loss" class="nav-link">loss</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseVariationalGaussianProcess.predict_log_density" class="nav-link">predict_log_density</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.SparseCVIGaussianProcess" class="nav-link">SparseCVIGaussianProcess</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.dist_q" class="nav-link">dist_q</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.update_sites" class="nav-link">update_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.loss" class="nav-link">loss</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.local_objective_and_gradients" class="nav-link">local_objective_and_gradients</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.local_objective" class="nav-link">local_objective</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.classic_elbo" class="nav-link">classic_elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.kernel" class="nav-link">kernel</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.dist_p" class="nav-link">dist_p</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SparseCVIGaussianProcess.likelihood" class="nav-link">likelihood</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.SpatioTemporalSparseVariational" class="nav-link">SpatioTemporalSparseVariational</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseVariational.dist_q" class="nav-link">dist_q</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseVariational.dist_p" class="nav-link">dist_p</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseVariational.posterior" class="nav-link">posterior</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.SpatioTemporalSparseCVI" class="nav-link">SpatioTemporalSparseCVI</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.dist_q" class="nav-link">dist_q</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.dist_p" class="nav-link">dist_p</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.projection_inducing_states_to_observations" class="nav-link">projection_inducing_states_to_observations</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.update_sites" class="nav-link">update_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.local_objective_and_gradients" class="nav-link">local_objective_and_gradients</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.SpatioTemporalSparseCVI.local_objective" class="nav-link">local_objective</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.VariationalGaussianProcess" class="nav-link">VariationalGaussianProcess</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.elbo" class="nav-link">elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.time_points" class="nav-link">time_points</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.observations" class="nav-link">observations</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.kernel" class="nav-link">kernel</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.likelihood" class="nav-link">likelihood</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.mean_function" class="nav-link">mean_function</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.dist_p" class="nav-link">dist_p</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.dist_q" class="nav-link">dist_q</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.posterior" class="nav-link">posterior</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.VariationalGaussianProcess.loss" class="nav-link">loss</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#markovflow.models.CVIGaussianProcess" class="nav-link">CVIGaussianProcess</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.CVIGaussianProcess.local_objective" class="nav-link">local_objective</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.CVIGaussianProcess.local_objective_and_gradients" class="nav-link">local_objective_and_gradients</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.CVIGaussianProcess.update_sites" class="nav-link">update_sites</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.CVIGaussianProcess.elbo" class="nav-link">elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.CVIGaussianProcess.classic_elbo" class="nav-link">classic_elbo</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#markovflow.models.CVIGaussianProcess.predict_log_density" class="nav-link">predict_log_density</a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="module-markovflow.models">
<span id="markovflow-models"></span><h1><a class="reference internal" href="#module-markovflow.models" title="markovflow.models"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models</span></code></a><a class="headerlink" href="#module-markovflow.models" title="Permalink to this headline">¶</a></h1>
<p>Package containing ready-to-use GP models.</p>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="gaussian_process_regression/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.gaussian_process_regression</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="iwvi/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.iwvi</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="models/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="pep/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.pep</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_pep/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.sparse_pep</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_variational/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.sparse_variational</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_variational_cvi/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.sparse_variational_cvi</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="spatio_temporal_variational/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.spatio_temporal_variational</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="variational/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.variational</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="variational_cvi/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markovflow.models.variational_cvi</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="markovflow.models.GaussianProcessRegression">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">GaussianProcessRegression</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chol_obs_covariance</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">gpflow.base.TensorType</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/gaussian_process_regression.html#GaussianProcessRegression"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="models/index.html#markovflow.models.models.MarkovFlowModel" title="markovflow.models.models.MarkovFlowModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.models.MarkovFlowModel</span></code></a></p>
<p>Performs GP regression.</p>
<p>The key reference is Chapter 2 of:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Gaussian</span> <span class="n">Processes</span> <span class="k">for</span> <span class="n">Machine</span> <span class="n">Learning</span>
<span class="n">Carl</span> <span class="n">Edward</span> <span class="n">Rasmussen</span> <span class="ow">and</span> <span class="n">Christopher</span> <span class="n">K</span><span class="o">.</span> <span class="n">I</span><span class="o">.</span> <span class="n">Williams</span>
<span class="n">The</span> <span class="n">MIT</span> <span class="n">Press</span><span class="p">,</span> <span class="mf">2006.</span> <span class="n">ISBN</span> <span class="mi">0</span><span class="o">-</span><span class="mi">262</span><span class="o">-</span><span class="mi">18253</span><span class="o">-</span><span class="n">X</span><span class="o">.</span>
</pre></div>
</div>
<p>This class uses the kernel and the time points to create a state space model.
GP regression is then a Kalman filter on that state space model using the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – A kernel defining a prior over functions.</p></li>
<li><p><strong>input_data</strong> – A tuple of <code class="docutils literal notranslate"><span class="pre">(time_points,</span> <span class="pre">observations)</span></code> containing the observed data:
time points of observations, with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p></li>
<li><p><strong>chol_obs_covariance</strong> – A <code class="xref py py-data docutils literal notranslate"><span class="pre">TensorType</span></code> containing
the Cholesky factor of the observation noise covariance,
with shape <code class="docutils literal notranslate"><span class="pre">[observation_dim,</span> <span class="pre">observation_dim]</span></code>.
a default None value will assume independent likelihood variance of 1.0</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.time_points">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">time_points</span></code> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.time_points" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the time points of observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.observations">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">observations</span></code> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.kernel">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">kernel</span></code> &#x2192; <a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the kernel of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.mean_function">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">mean_function</span></code> &#x2192; <a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.mean_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the mean function of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.loss">
<code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the loss, which is the negative log likelihood.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain a posterior process for inference.</p>
<p>For this class, this is the <a class="reference internal" href="../posterior/index.html#markovflow.posterior.AnalyticPosteriorProcess" title="markovflow.posterior.AnalyticPosteriorProcess"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticPosteriorProcess</span></code></a>
built from the Kalman filter.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.GaussianProcessRegression.log_likelihood">
<code class="sig-name descname"><span class="pre">log_likelihood</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.GaussianProcessRegression.log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the log likelihood of the observations given the kernel parameters.</p>
<p>In other words, <span class="math notranslate nohighlight">\(log p(y_{1...T} | ϑ)\)</span> for some parameters <span class="math notranslate nohighlight">\(ϑ\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A scalar tensor (summed over the batch shape and the whole trajectory).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.ImportanceWeightedVI">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">ImportanceWeightedVI</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_importance_samples</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_distribution</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../state_space_model/index.html#markovflow.state_space_model.StateSpaceModel" title="markovflow.state_space_model.StateSpaceModel"><span class="pre">markovflow.state_space_model.StateSpaceModel</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/iwvi.html#ImportanceWeightedVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.ImportanceWeightedVI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="sparse_variational/index.html#markovflow.models.sparse_variational.SparseVariationalGaussianProcess" title="markovflow.models.sparse_variational.SparseVariationalGaussianProcess"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.sparse_variational.SparseVariationalGaussianProcess</span></code></a></p>
<p>Performs importance-weighted variational inference (IWVI).</p>
<p>The <a class="reference external" href="https://papers.nips.cc/paper/7699-importance-weighting-and-variational-inference.pdf">key reference</a> is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">domke2018importance</span><span class="p">,</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Importance</span> <span class="n">weighting</span> <span class="ow">and</span> <span class="n">variational</span> <span class="n">inference</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Domke</span><span class="p">,</span> <span class="n">Justin</span> <span class="ow">and</span> <span class="n">Sheldon</span><span class="p">,</span> <span class="n">Daniel</span> <span class="n">R</span><span class="p">},</span>
  <span class="n">booktitle</span><span class="o">=</span><span class="p">{</span><span class="n">Advances</span> <span class="ow">in</span> <span class="n">neural</span> <span class="n">information</span> <span class="n">processing</span> <span class="n">systems</span><span class="p">},</span>
  <span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">4470</span><span class="o">--</span><span class="mi">4479</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2018</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The idea is based on the observation that an estimator of the evidence lower bound (ELBO)
can be obtained from an importance weight <span class="math notranslate nohighlight">\(w\)</span>:</p>
<div class="math notranslate nohighlight">
\[L₁ = log w(x₁),    x₁ ~ q(x)\]</div>
<p>…where <span class="math notranslate nohighlight">\(x\)</span> is the latent variable of the model (a GP, or set of GPs in our case)
and the function <span class="math notranslate nohighlight">\(w\)</span> is:</p>
<div class="math notranslate nohighlight">
\[w(x) = p(y | x) p(x) / q(x)\]</div>
<p>It follows that:</p>
<div class="math notranslate nohighlight">
\[ELBO = 𝔼ₓ₁[ L₁ ]\]</div>
<p>…and:</p>
<div class="math notranslate nohighlight">
\[log p(y) = log 𝔼ₓ₁[ w(x₁) ]\]</div>
<p>It turns out that there are a series of lower bounds given by taking multiple importance
samples:</p>
<div class="math notranslate nohighlight">
\[Lₙ = log (1/n) Σᵢⁿ w(xᵢ),     xᵢ ~ q(x)\]</div>
<p>And we have the relation:</p>
<div class="math notranslate nohighlight">
\[log p(y) &gt;= 𝔼[Lₙ] &gt;= 𝔼[Lₙ₋₁] &gt;= ... &gt;= 𝔼[L₁] = ELBO\]</div>
<p>This means that we can improve tightness of the ELBO to the log marginal likelihood by
increasing <span class="math notranslate nohighlight">\(n\)</span>, which we refer to in this class as <code class="xref any docutils literal notranslate"><span class="pre">num_importance_samples</span></code>.
The trade-offs are:</p>
<blockquote>
<div><ul class="simple">
<li><p>The objective function is now always stochastic, even for cases where the ELBO
of the parent class is non-stochastic</p></li>
<li><p>We have to do more computations (evaluate the weights <span class="math notranslate nohighlight">\(n\)</span> times)</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>inducing_points</strong> – The points in time on which inference should be performed,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>likelihood</strong> – A likelihood.</p></li>
<li><p><strong>num_importance_samples</strong> – The number of samples for the importance-weighted estimator.</p></li>
<li><p><strong>initial_distribution</strong> – An initial configuration for the variational distribution,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.ImportanceWeightedVI.elbo">
<code class="sig-name descname"><span class="pre">elbo</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.ImportanceWeightedVI.elbo" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the importance-weighted ELBO using K samples. The procedure is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.</span><span class="o">..</span><span class="n">K</span><span class="p">:</span>
    <span class="n">uₖ</span> <span class="o">~</span> <span class="n">q</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="n">sₖ</span> <span class="o">~</span> <span class="n">p</span><span class="p">(</span><span class="n">s</span> <span class="o">|</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">wₖ</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">y</span> <span class="o">|</span> <span class="n">sₖ</span><span class="p">)</span><span class="n">p</span><span class="p">(</span><span class="n">uₖ</span><span class="p">)</span> <span class="o">/</span> <span class="n">q</span><span class="p">(</span><span class="n">uₖ</span><span class="p">)</span>

<span class="n">ELBO</span> <span class="o">=</span> <span class="n">log</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">K</span><span class="p">)</span> <span class="n">Σₖwₖ</span>
</pre></div>
</div>
<p>Everything is computed in log-space for stability. Note that gradients
of this ELBO may have high variance with regard to the variational parameters;
see the DREGS gradient estimator method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – <p>A tuple of time points and observations containing the data at which
to calculate the loss for training the model:</p>
<ul class="simple">
<li><p>A tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>A tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.ImportanceWeightedVI.dregs_objective">
<code class="sig-name descname"><span class="pre">dregs_objective</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.ImportanceWeightedVI.dregs_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a scalar tensor that, when differentiated using <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/gradients" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.gradients</span></code></a>,
produces the DREGS variance controlled gradient.</p>
<p>See <a class="reference external" href="https://openreview.net/pdf?id=HkG3e205K7">“Doubly Reparameterized Gradient Estimators For Monte Carlo Objectives”</a> for a derivation.</p>
<p>We recommend using these gradients for training variational
parameters and gradients of the importance-weighted ELBO for training hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – <p>A tuple of time points and observations containing the data at which
to calculate the loss for training the model:</p>
<ul class="simple">
<li><p>A tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>A tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar tensor.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.MarkovFlowModel">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">MarkovFlowModel</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/models.html#MarkovFlowModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.MarkovFlowModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Module" title="(in TensorFlow v2.4)"><code class="docutils literal notranslate"><span class="pre">tf.Module</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.10)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>Abstract class representing Markovflow models that depend on input data.</p>
<p>All Markovflow models are <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Module" title="(in TensorFlow v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorFlow</span> <span class="pre">Modules</span></code></a>, so it is possible to obtain
trainable variables via the <code class="xref py py-attr docutils literal notranslate"><span class="pre">trainable_variables</span></code> attribute. You can combine this with
the <a class="reference internal" href="#markovflow.models.MarkovFlowModel.loss" title="markovflow.models.MarkovFlowModel.loss"><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss()</span></code></a> method to train the model. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">optimization_step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
</pre></div>
</div>
<p>Call the <a class="reference internal" href="#markovflow.models.MarkovFlowModel.predict_f" title="markovflow.models.MarkovFlowModel.predict_f"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_f()</span></code></a> method to predict marginal function values at future time points.
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span><span class="p">,</span> <span class="n">variance</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">validation_data_tensor</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Markovflow models that extend this class must implement the <a class="reference internal" href="#markovflow.models.MarkovFlowModel.loss" title="markovflow.models.MarkovFlowModel.loss"><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss()</span></code></a>
method and <a class="reference internal" href="#markovflow.models.MarkovFlowModel.posterior" title="markovflow.models.MarkovFlowModel.posterior"><code class="xref py py-attr docutils literal notranslate"><span class="pre">posterior</span></code></a> attribute.</p>
</div>
<dl class="py method">
<dt id="markovflow.models.MarkovFlowModel.loss">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.MarkovFlowModel.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain the loss, which you can use to train the model.
It should always return a scalar.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.10)"><strong>NotImplementedError</strong></a> – Must be implemented in derived classes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowModel.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.MarkovFlowModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a posterior process from the model, which can be used for inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.10)"><strong>NotImplementedError</strong></a> – Must be implemented in derived classes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowModel.predict_state">
<code class="sig-name descname"><span class="pre">predict_state</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_time_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#markovflow.models.MarkovFlowModel.predict_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict state at <code class="xref any docutils literal notranslate"><span class="pre">new_time_points</span></code>. Note these time points should be sorted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_time_points</strong> – Time points to generate observations for, with shape
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,]</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted mean and covariance for the new time points, with respective shapes
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">state_dim]</span></code>
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">state_dim,</span> <span class="pre">state_dim]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowModel.predict_f">
<code class="sig-name descname"><span class="pre">predict_f</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_time_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#markovflow.models.MarkovFlowModel.predict_f" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict marginal function values at <code class="xref any docutils literal notranslate"><span class="pre">new_time_points</span></code>. Note these
time points should be sorted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>new_time_points</strong> – Time points to generate observations for, with shape
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points]</span></code>.</p></li>
<li><p><strong>full_output_cov</strong> – Either full output covariance (<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or marginal
variances (<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted mean and covariance for the new time points, with respective shapes
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">output_dim]</span></code> and either
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">output_dim,</span> <span class="pre">output_dim]</span></code> or
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">output_dim]</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.MarkovFlowSparseModel">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">MarkovFlowSparseModel</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/models.html#MarkovFlowSparseModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.MarkovFlowSparseModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Module" title="(in TensorFlow v2.4)"><code class="docutils literal notranslate"><span class="pre">tf.Module</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.10)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
<p>Abstract class representing Markovflow models that do not need to store the training
data (<span class="math notranslate nohighlight">\(X, Y\)</span>) in the model to approximate the
posterior predictions <span class="math notranslate nohighlight">\(p(f*|X, Y, x*)\)</span>.</p>
<p>This currently applies only to sparse variational models.</p>
<p>The <code class="xref any docutils literal notranslate"><span class="pre">optimization_step</span></code> method should typically be used to train the model. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">time_points</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">observations</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">optimization_step</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
</pre></div>
</div>
<p>Call the <a class="reference internal" href="#markovflow.models.MarkovFlowSparseModel.predict_f" title="markovflow.models.MarkovFlowSparseModel.predict_f"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_f()</span></code></a> method to predict marginal function values at future time points.
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span><span class="p">,</span> <span class="n">variance</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">validation_data_tensor</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Markovflow models that extend this class must implement the <a class="reference internal" href="#markovflow.models.MarkovFlowSparseModel.loss" title="markovflow.models.MarkovFlowSparseModel.loss"><code class="xref py py-meth docutils literal notranslate"><span class="pre">loss()</span></code></a>
method and <a class="reference internal" href="#markovflow.models.MarkovFlowSparseModel.posterior" title="markovflow.models.MarkovFlowSparseModel.posterior"><code class="xref py py-attr docutils literal notranslate"><span class="pre">posterior</span></code></a> attribute.</p>
</div>
<dl class="py method">
<dt id="markovflow.models.MarkovFlowSparseModel.loss">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.MarkovFlowSparseModel.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain the loss, which can be used to train the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – <p>A tuple of time points and observations containing the data at which
to calculate the loss for training the model:</p>
<ul class="simple">
<li><p>A tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>A tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.10)"><strong>NotImplementedError</strong></a> – Must be implemented in derived classes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowSparseModel.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.MarkovFlowSparseModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain a posterior process from the model, which can be used for inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.10)"><strong>NotImplementedError</strong></a> – Must be implemented in derived classes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowSparseModel.predict_state">
<code class="sig-name descname"><span class="pre">predict_state</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_time_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#markovflow.models.MarkovFlowSparseModel.predict_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict state at <code class="xref any docutils literal notranslate"><span class="pre">new_time_points</span></code>. Note these time points should be sorted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_time_points</strong> – Time points to generate observations for, with shape
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,]</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted mean and covariance for the new time points, with respective shapes
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">state_dim]</span></code>
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">state_dim,</span> <span class="pre">state_dim]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowSparseModel.predict_f">
<code class="sig-name descname"><span class="pre">predict_f</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_time_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#markovflow.models.MarkovFlowSparseModel.predict_f" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict marginal function values at <code class="xref any docutils literal notranslate"><span class="pre">new_time_points</span></code>. Note these
time points should be sorted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>new_time_points</strong> – Time points to generate observations for, with shape
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points]</span></code>.</p></li>
<li><p><strong>full_output_cov</strong> – Either full output covariance (<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or marginal
variances (<code class="xref any docutils literal notranslate"><span class="pre">FalseF</span></code>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted mean and covariance for the new time points, with respective shapes
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">output_dim]</span></code> and either
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">output_dim,</span> <span class="pre">output_dim]</span></code> or
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_new_time_points,</span> <span class="pre">output_dim]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.MarkovFlowSparseModel.predict_log_density">
<code class="sig-name descname"><span class="pre">predict_log_density</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.MarkovFlowSparseModel.predict_log_density" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log density of the data. That is:</p>
<div class="math notranslate nohighlight">
\[log ∫ p(yᵢ=Yᵢ|Fᵢ)q(Fᵢ) dFᵢ\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> – <p>A tuple of time points and observations containing the data at which
to calculate the loss for training the model:</p>
<ul>
<li><p>A tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>A tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code></p></li>
</ul>
</p></li>
<li><p><strong>full_output_cov</strong> – Either full output covariance (<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or marginal
variances (<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted log density at input time points, with shape
<code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.PowerExpectationPropagation">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">PowerExpectationPropagation</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../likelihoods/index.html#markovflow.likelihoods.PEPScalarLikelihood" title="markovflow.likelihoods.PEPScalarLikelihood"><span class="pre">markovflow.likelihoods.PEPScalarLikelihood</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/pep.html#PowerExpectationPropagation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="variational_cvi/index.html#markovflow.models.variational_cvi.GaussianProcessWithSitesBase" title="markovflow.models.variational_cvi.GaussianProcessWithSitesBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.variational_cvi.GaussianProcessWithSitesBase</span></code></a></p>
<p>This is an approximate inference called Power Expectation Propagation.</p>
<p>Approximates a the posterior of a model with GP prior and a general likelihood
using a Gaussian posterior parameterized with Gaussian sites.</p>
<p>The following notation is used:</p>
<blockquote>
<div><ul class="simple">
<li><p>x - the time points of the training data.</p></li>
<li><p>y - observations corresponding to time points x.</p></li>
<li><p>s(.) - the latent state of the Markov chain</p></li>
<li><p>f(.) - the noise free predictions of the model</p></li>
<li><p>p(y | f) - the likelihood</p></li>
<li><p>t(f) - a site (indices will refer to the associated data point)</p></li>
<li><p>p(.) the prior distribution</p></li>
<li><p>q(.) the variational distribution</p></li>
</ul>
</div></blockquote>
<p>We use the state space formulation of Markovian Gaussian Processes that specifies:
the conditional density of neighbouring latent states: p(xₖ₊₁| xₖ)
how to read out the latent process from these states: fₖ = H xₖ</p>
<p>The likelihood links data to the latent process and p(yₖ | fₖ).
We would like to approximate the posterior over the latent state space model of this model.</p>
<p>We parameterize the joint posterior using sites tₖ(fₖ)</p>
<blockquote>
<div><p>p(x, y) = p(x) ∏ₖ tₖ(fₖ)</p>
</div></blockquote>
<p>where tₖ(fₖ) are univariate Gaussian sites parameterized in the natural form</p>
<blockquote>
<div><p>t(f) = exp(𝞰ᵀφ(f) - A(𝞰)), where 𝞰=[η₁,η₂] and 𝛗(f)=[f,f²]</p>
</div></blockquote>
<p>(note: the subscript k has been omitted for simplicity)</p>
<p>The site update of the sites are given by the classic EP update rules as described in:</p>
<dl class="simple">
<dt>&#64;techreport{seeger2005expectation,</dt><dd><p>title={Expectation propagation for exponential families},
author={Seeger, Matthias},
year={2005}</p>
</dd>
</dl>
<p>}</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>input_data</strong> – A tuple of <code class="docutils literal notranslate"><span class="pre">(time_points,</span> <span class="pre">observations)</span></code> containing the observed data:
time points of observations, with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p></li>
<li><p><strong>likelihood</strong> – A likelihood.
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>learning_rate</strong> – the learning rate of the algorithm</p></li>
<li><p><strong>alpha</strong> – the power as in Power Expectation propagation</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.local_objective">
<code class="sig-name descname"><span class="pre">local_objective</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.local_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Local objective of the PEP algorithm : log E_q(f) p(y|f)ᵃ</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.local_objective_gradients">
<code class="sig-name descname"><span class="pre">local_objective_gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.local_objective_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradients of the local objective of the PEP algorithm wrt to the predictive mean</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.mask_indices">
<code class="sig-name descname"><span class="pre">mask_indices</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">exclude_indices</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.mask_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary mask (cast to float), 0 for the excluded indices, 1 for the rest</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.compute_cavity_from_marginals">
<code class="sig-name descname"><span class="pre">compute_cavity_from_marginals</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">marginals</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.compute_cavity_from_marginals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute cavity from marginals
:param marginals: list of tensors</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.compute_cavity">
<code class="sig-name descname"><span class="pre">compute_cavity</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.compute_cavity" title="Permalink to this definition">¶</a></dt>
<dd><p>The cavity distributions for all data points.
This corresponds to the marginal distribution qᐠⁿ(fₙ) of qᐠⁿ(f) = q(f)/tₙ(fₙ)ᵃ</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.compute_log_norm">
<code class="sig-name descname"><span class="pre">compute_log_norm</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.compute_log_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute log normalizer</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.update_sites">
<code class="sig-name descname"><span class="pre">update_sites</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">site_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.update_sites" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the site updates and perform one update step
:param site_indices: list of indices to be updated</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.elbo">
<code class="sig-name descname"><span class="pre">elbo</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.elbo" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the marginal log marginal likelihood of the approximate  joint p(s, y)</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.energy">
<code class="sig-name descname"><span class="pre">energy</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.energy" title="Permalink to this definition">¶</a></dt>
<dd><p>PEP Energy</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.PowerExpectationPropagation.predict_log_density">
<code class="sig-name descname"><span class="pre">predict_log_density</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.PowerExpectationPropagation.predict_log_density" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log density of the data at the new data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> – A tuple of time points and observations containing the data at which
to calculate the loss for training the model:
a tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
a tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p></li>
<li><p><strong>full_output_cov</strong> – Either full output covariance (<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or marginal
variances (<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.SparsePowerExpectationPropagation">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">SparsePowerExpectationPropagation</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../likelihoods/index.html#markovflow.likelihoods.PEPScalarLikelihood" title="markovflow.likelihoods.PEPScalarLikelihood"><span class="pre">markovflow.likelihoods.PEPScalarLikelihood</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/sparse_pep.html#SparsePowerExpectationPropagation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="models/index.html#markovflow.models.models.MarkovFlowSparseModel" title="markovflow.models.models.MarkovFlowSparseModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.models.MarkovFlowSparseModel</span></code></a></p>
<p>This is the  Sparse Power Expectation Propagation Algorithm</p>
<p>Approximates a the posterior of a model with GP prior and a general likelihood
using a Gaussian posterior parameterized with Gaussian sites on
inducing states u at inducing points z.</p>
<p>The following notation is used:</p>
<blockquote>
<div><ul class="simple">
<li><p>x - the time points of the training data.</p></li>
<li><p>z - the time points of the inducing/pseudo points.</p></li>
<li><p>y - observations corresponding to time points x.</p></li>
<li><p>s(.) - the continuous time latent state process</p></li>
<li><p>u = s(z) - the discrete inducing latent state space model</p></li>
<li><p>f(.) - the noise free predictions of the model</p></li>
<li><p>p(y | f) - the likelihood</p></li>
<li><p>t(u) - a site (indices will refer to the associated data point)</p></li>
<li><p>p(.) the prior distribution</p></li>
<li><p>q(.) the variational distribution</p></li>
</ul>
</div></blockquote>
<p>We use the state space formulation of Markovian Gaussian Processes that specifies:
the conditional density of neighbouring latent states: p(sₖ₊₁| sₖ)
how to read out the latent process from these states: fₖ = H sₖ</p>
<p>The likelihood links data to the latent process and p(yₖ | fₖ).
We would like to approximate the posterior over the latent state space model of this model.</p>
<p>To approximate the posterior, we maximise the evidence lower bound (ELBO) (ℒ) with
respect to the parameters of the variational distribution, since:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>log p(y) = ℒ(q) + KL[q(s) ‖ p(s | y)]
</pre></div>
</div>
<p>…where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>ℒ(q) = ∫ log(p(s, y) / q(s)) q(s) ds
</pre></div>
</div>
<p>We parameterize the variational posterior through M sites tₘ(vₘ)</p>
<blockquote>
<div><p>q(s) = p(s) ∏ₘ  tₘ(vₘ)</p>
</div></blockquote>
<p>where tₘ(vₘ) are multivariate Gaussian sites on vₘ = [uₘ, uₘ₊₁],
i.e. consecutive inducing states.</p>
<p>The sites are parameterized in the natural form</p>
<blockquote>
<div><p>t(v) = exp(𝜽ᵀφ(v) - A(𝜽)), where 𝜽=[θ₁, θ₂] and 𝛗(u)=[v, vᵀv]</p>
</div></blockquote>
<p>with 𝛗(v) are the sufficient statistics and 𝜽 the natural parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>inducing_points</strong> – The points in time on which inference should be performed,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>likelihood</strong> – A likelihood.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>learning_rate</strong> – the learning rate</p></li>
<li><p><strong>alpha</strong> – power as in Power Expectation Propagation</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.posterior">
<code class="sig-name descname"><span class="pre">posterior</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Posterior Process</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.mask_indices">
<code class="sig-name descname"><span class="pre">mask_indices</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">exclude_indices</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.mask_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary mask to exclude data indices
:param exclude_indices:</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.back_project_nats">
<code class="sig-name descname"><span class="pre">back_project_nats</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nat1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nat2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.back_project_nats" title="Permalink to this definition">¶</a></dt>
<dd><p>back project natural gradient associated to time points to their associated
inducing sites.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.local_objective">
<code class="sig-name descname"><span class="pre">local_objective</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.local_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Local objective of the PEP algorithm : log E_q(f) p(y|f)ᵃ</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.local_objective_gradients">
<code class="sig-name descname"><span class="pre">local_objective_gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fx_mus</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fx_covs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.local_objective_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradients of the local objective of the PEP algorithm wrt to the predictive mean</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.fraction_sites">
<code class="sig-name descname"><span class="pre">fraction_sites</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.fraction_sites" title="Permalink to this definition">¶</a></dt>
<dd><p>for all segment indexed m of consecutive inducing points [z_m, z_m+1[,
this counts the time points t falling in that segment:
c(m) = #{t, z_m &lt;= t &lt; z_m+1} and returns 1/c(m) or 0 when c(m)=0</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>time_points</strong> – tensor of shape batch_shape + [num_data]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor of shape batch_shape + [num_data]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_posterior_ssm">
<code class="sig-name descname"><span class="pre">compute_posterior_ssm</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nat1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nat2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_posterior_ssm" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the variational posterior distribution on the vector of inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.dist_q">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_q</span></code><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.dist_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the variational posterior distribution on the vector of inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_marginals">
<code class="sig-name descname"><span class="pre">compute_marginals</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_marginals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute pairwise marginals</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.remove_cavity_from_marginals">
<code class="sig-name descname"><span class="pre">remove_cavity_from_marginals</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginals</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.remove_cavity_from_marginals" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove cavity from marginals
:param time_points:
:param marginals: pairwise mean and covariance tensors</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_cavity_state">
<code class="sig-name descname"><span class="pre">compute_cavity_state</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_cavity_state" title="Permalink to this definition">¶</a></dt>
<dd><p>The cavity distributions for data points at input time_points.
This corresponds to the marginal distribution qᐠⁿ(fₙ) of qᐠⁿ(s) = q(s)/tₘ(vₘ)ᵝᵃ,
where β = a * (1 / #time points <code class="xref any docutils literal notranslate"><span class="pre">touching</span></code> site tₘ)</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_cavity">
<code class="sig-name descname"><span class="pre">compute_cavity</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_cavity" title="Permalink to this definition">¶</a></dt>
<dd><p>Cavity on f
:param time_points: time points</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_new_sites">
<code class="sig-name descname"><span class="pre">compute_new_sites</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_new_sites" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the site updates and perform one update step.
:param input_data: A tuple of time points and observations containing the data from which</p>
<blockquote>
<div><p>to calculate the the updates:
a tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
a tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_log_norm">
<code class="sig-name descname"><span class="pre">compute_log_norm</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_log_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the site updates and perform one update step.
:param input_data: A tuple of time points and observations containing the data from which</p>
<blockquote>
<div><p>to calculate the the updates:
a tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
a tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_num_data_per_interval">
<code class="sig-name descname"><span class="pre">compute_num_data_per_interval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_num_data_per_interval" title="Permalink to this definition">¶</a></dt>
<dd><p>compute fraction of site per data point</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.compute_fraction">
<code class="sig-name descname"><span class="pre">compute_fraction</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">time_points</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.compute_fraction" title="Permalink to this definition">¶</a></dt>
<dd><p>compute fraction of site per data point</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.update_sites">
<code class="sig-name descname"><span class="pre">update_sites</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.update_sites" title="Permalink to this definition">¶</a></dt>
<dd><p>apply updates</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.energy">
<code class="sig-name descname"><span class="pre">energy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.energy" title="Permalink to this definition">¶</a></dt>
<dd><p>The PEP energy : ∫ ds p(s) 𝚷_m t_m(v_m)
:param input_data: input data</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.loss">
<code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the loss, which is the negative evidence lower bound (ELBO).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – A tuple of time points and observations containing the data at which
to calculate the loss for training the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.dist_p">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_p</span></code> &#x2192; <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.dist_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the prior <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><code class="xref any py py-class docutils literal notranslate"><span class="pre">GaussMarkovDistribution</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.kernel">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">kernel</span></code> &#x2192; <a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the kernel of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.classic_elbo">
<code class="sig-name descname"><span class="pre">classic_elbo</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.classic_elbo" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Computes the ELBO the classic way:</dt><dd><p>ℒ(q) = Σᵢ ∫ log(p(yᵢ | f)) q(f) df - KL[q(f) ‖ p(f)]</p>
</dd>
</dl>
<p>Note: this is mostly for testing purposes and not to be used for optimization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – A tuple of time points and observations</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar tensor representing the ELBO.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparsePowerExpectationPropagation.predict_log_density">
<code class="sig-name descname"><span class="pre">predict_log_density</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparsePowerExpectationPropagation.predict_log_density" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log density of the data at the new data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> – A tuple of time points and observations containing the data at which
to calculate the loss for training the model:
a tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
a tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p></li>
<li><p><strong>full_output_cov</strong> – Either full output covariance (<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or marginal
variances (<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.SparseVariationalGaussianProcess">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">SparseVariationalGaussianProcess</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_distribution</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/sparse_variational.html#SparseVariationalGaussianProcess"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="models/index.html#markovflow.models.models.MarkovFlowSparseModel" title="markovflow.models.models.MarkovFlowSparseModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.models.MarkovFlowSparseModel</span></code></a></p>
<p>Approximate a <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">GaussMarkovDistribution</span></code></a> with a general
likelihood using a Gaussian posterior. Additionally uses a number of pseudo, or inducing,
points to represent the distribution over a typically larger number of data points.</p>
<p>The following notation is used:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> - the time points of the training data</p></li>
<li><p><span class="math notranslate nohighlight">\(z\)</span> - the time points of the inducing/pseudo points</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> - observations corresponding to time points <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(s(.)\)</span> - the latent state of the Markov chain</p></li>
<li><p><span class="math notranslate nohighlight">\(f(.)\)</span> - the noise free predictions of the model</p></li>
<li><p><span class="math notranslate nohighlight">\(p(y | f)\)</span> - the likelihood</p></li>
<li><p><span class="math notranslate nohighlight">\(p(.)\)</span> - the true distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(q(.)\)</span> - the variational distribution</p></li>
</ul>
</div></blockquote>
<p>Subscript is used to denote dependence for notational convenience, for
example <span class="math notranslate nohighlight">\(fₖ === f(k)\)</span>.</p>
<p>With a prior generative model comprising a Gauss-Markov distribution, an emission model and an
arbitrary likelihood on the emitted variables, these define:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p(xₖ₊₁| xₖ)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(fₖ = H xₖ\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p(yₖ | fₖ)\)</span></p></li>
</ul>
</div></blockquote>
<p>As per a <a class="reference internal" href="variational/index.html#markovflow.models.variational.VariationalGaussianProcess" title="markovflow.models.variational.VariationalGaussianProcess"><code class="xref py py-class docutils literal notranslate"><span class="pre">VariationalGaussianProcess</span></code></a>
(VGP) model, we have:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}&amp;log p(y) &gt;= ℒ(q)\\&amp;ℒ(q) = Σᵢ ∫ log(p(yᵢ | f)) q(f) df - KL[q(f) ‖ p(f)]\end{aligned}\end{align} \]</div>
<p>…where <span class="math notranslate nohighlight">\(f\)</span> is defined over the entire function space.</p>
<p>Here this reduces to the joint of the evidence lower bound (ELBO) defined over both the
data <span class="math notranslate nohighlight">\(x\)</span> and the inducing points <span class="math notranslate nohighlight">\(z\)</span>, which we rewrite as:</p>
<div class="math notranslate nohighlight">
\[ℒ(q(x, z)) = Σᵢ ∫ log(p(yᵢ | fₓ)) q(fₓ) df - KL[q(f(z)) ‖ p(f(z))]\]</div>
<p>This turns the inference problem into an optimisation problem: find the optimal <span class="math notranslate nohighlight">\(q\)</span>.</p>
<p>The first term is the variational expectations and have the same form as a VGP model.
However, we must now use use the inducing states to predict the marginals of the
variational distribution at the original data points.</p>
<p>The second is the KL from the prior to the approximation, but evaluated at the inducing points.</p>
<p>The key reference is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{,</span>
    <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Doubly</span> <span class="n">Sparse</span> <span class="n">Variational</span> <span class="n">Gaussian</span> <span class="n">Processes</span><span class="p">},</span>
    <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Adam</span><span class="p">,</span> <span class="n">Eleftheriadis</span><span class="p">,</span> <span class="n">Artemev</span><span class="p">,</span> <span class="n">Durrande</span><span class="p">,</span> <span class="n">Hensman</span><span class="p">},</span>
    <span class="n">booktitle</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">pages</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">year</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">organization</span><span class="o">=</span><span class="p">{}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since this class extends <a class="reference internal" href="models/index.html#markovflow.models.models.MarkovFlowSparseModel" title="markovflow.models.models.MarkovFlowSparseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">MarkovFlowSparseModel</span></code></a>,
it does not depend on input data. Input data is passed during the optimisation
step as a tuple of time points and observations.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>likelihood</strong> – A likelihood.</p></li>
<li><p><strong>inducing_points</strong> – The points in time on which inference should be performed,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>num_data</strong> – The total number of observations.
(relevant when feeding in external minibatches).</p></li>
<li><p><strong>initial_distribution</strong> – An initial configuration for the variational distribution,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.elbo">
<code class="sig-name descname"><span class="pre">elbo</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.elbo" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the evidence lower bound (ELBO) <span class="math notranslate nohighlight">\(log p(y)\)</span>. We rewrite this as:</p>
<div class="math notranslate nohighlight">
\[ℒ(q(x, z)) = Σᵢ ∫ log(p(yᵢ | fₓ)) q(fₓ) df - KL[q(s(z)) ‖ p(s(z))]\]</div>
<p>The first term is the ‘variational expectation’ (VE), and has the same form as per a
<a class="reference internal" href="variational/index.html#markovflow.models.variational.VariationalGaussianProcess" title="markovflow.models.variational.VariationalGaussianProcess"><code class="xref py py-class docutils literal notranslate"><span class="pre">VariationalGaussianProcess</span></code></a> (VGP) model. However,
we must now use the inducing states to predict the marginals of the
variational distribution at the original data points.</p>
<p>The second is the KL divergence from the prior to the approximation, but evaluated at the
inducing points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – <p>A tuple of time points and observations containing the data at which
to calculate the loss for training the model:</p>
<ul class="simple">
<li><p>A tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>A tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar tensor (summed over the batch_shape dimension) representing the ELBO.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.time_points">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">time_points</span></code> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.time_points" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the time points of the sparse process which essentially are the locations of the
inducing points.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>. Same as inducing inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.kernel">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">kernel</span></code> &#x2192; <a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the kernel of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.likelihood">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">likelihood</span></code> &#x2192; <span class="pre">gpflow.likelihoods.Likelihood</span><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the likelihood of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.mean_function">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">mean_function</span></code> &#x2192; <a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.mean_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the mean function of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.dist_p">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_p</span></code> &#x2192; <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.dist_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the prior Gauss-Markov distribution.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.dist_q">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_q</span></code> &#x2192; <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.dist_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the variational distribution as a Gauss-Markov distribution.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain a posterior process for inference.</p>
<p>For this class this is the <a class="reference internal" href="../posterior/index.html#markovflow.posterior.AnalyticPosteriorProcess" title="markovflow.posterior.AnalyticPosteriorProcess"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticPosteriorProcess</span></code></a>
built from the variational distribution. This will be a locally optimal
variational approximation of the posterior after optimisation.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.loss">
<code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the loss, which is the negative evidence lower bound (ELBO).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – <p>A tuple of time points and observations containing the data at which
to calculate the loss for training the model:</p>
<ul class="simple">
<li><p>A tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>A tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseVariationalGaussianProcess.predict_log_density">
<code class="sig-name descname"><span class="pre">predict_log_density</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparseVariationalGaussianProcess.predict_log_density" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log density of the data at the new data points.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.SparseCVIGaussianProcess">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">SparseCVIGaussianProcess</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_points</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/sparse_variational_cvi.html#SparseCVIGaussianProcess"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="models/index.html#markovflow.models.models.MarkovFlowSparseModel" title="markovflow.models.models.MarkovFlowSparseModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.models.MarkovFlowSparseModel</span></code></a></p>
<p>This is an alternative parameterization to the <a class="reference internal" href="#markovflow.models.SparseVariationalGaussianProcess" title="markovflow.models.SparseVariationalGaussianProcess"><code class="xref any py py-class docutils literal notranslate"><span class="pre">SparseVariationalGaussianProcess</span></code></a></p>
<p>Approximates a the posterior of a model with GP prior and a general likelihood
using a Gaussian posterior parameterized with Gaussian sites on
inducing states u at inducing points z.</p>
<p>The following notation is used:</p>
<blockquote>
<div><ul class="simple">
<li><p>x - the time points of the training data.</p></li>
<li><p>z - the time points of the inducing/pseudo points.</p></li>
<li><p>y - observations corresponding to time points x.</p></li>
<li><p>s(.) - the continuous time latent state process</p></li>
<li><p>u = s(z) - the discrete inducing latent state space model</p></li>
<li><p>f(.) - the noise free predictions of the model</p></li>
<li><p>p(y | f) - the likelihood</p></li>
<li><p>t(u) - a site (indices will refer to the associated data point)</p></li>
<li><p>p(.) the prior distribution</p></li>
<li><p>q(.) the variational distribution</p></li>
</ul>
</div></blockquote>
<p>We use the state space formulation of Markovian Gaussian Processes that specifies:
the conditional density of neighbouring latent states: p(sₖ₊₁| sₖ)
how to read out the latent process from these states: fₖ = H sₖ</p>
<p>The likelihood links data to the latent process and p(yₖ | fₖ).
We would like to approximate the posterior over the latent state space model of this model.</p>
<p>To approximate the posterior, we maximise the evidence lower bound (ELBO) (ℒ) with
respect to the parameters of the variational distribution, since:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>log p(y) = ℒ(q) + KL[q(s) ‖ p(s | y)]
</pre></div>
</div>
<p>…where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>ℒ(q) = ∫ log(p(s, y) / q(s)) q(s) ds
</pre></div>
</div>
<p>We parameterize the variational posterior through M sites tₘ(vₘ)</p>
<blockquote>
<div><p>q(s) = p(s) ∏ₘ  tₘ(vₘ)</p>
</div></blockquote>
<p>where tₘ(vₘ) are multivariate Gaussian sites on vₘ = [uₘ, uₘ₊₁],
i.e. consecutive inducing states.</p>
<p>The sites are parameterized in the natural form</p>
<blockquote>
<div><p>t(v) = exp(𝜽ᵀφ(v) - A(𝜽)), where 𝜽=[θ₁, θ₂] and 𝛗(u)=[Wv, WᵀvᵀvW]</p>
</div></blockquote>
<p>with 𝛗(v) are the sufficient statistics and 𝜽 the natural parameters
and W is the projection of the conditional mean E_p(f|v)[f] = W v</p>
<p>Each data point indexed k contributes a fraction of the site it belongs to.
If vₘ = [uₘ, uₘ₊₁], and zₘ &lt; xₖ &lt;= zₘ₊₁, then xₖ <code class="xref any docutils literal notranslate"><span class="pre">belongs</span></code> to vₘ.</p>
<p>The natural gradient update of the sites are similar to that of the
CVIGaussianProcess except that they apply to a different parameterization of
the sites</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>inducing_points</strong> – The points in time on which inference should be performed,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>likelihood</strong> – A likelihood.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>learning_rate</strong> – the learning rate.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.dist_q">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_q</span></code><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.dist_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the variational posterior distribution on the vector of inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.update_sites">
<code class="sig-name descname"><span class="pre">update_sites</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.update_sites" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform one joint update of the Gaussian sites</dt><dd><p>𝜽ₘ ← ρ𝜽ₘ + (1-ρ)𝐠ₘ</p>
</dd>
</dl>
<p>Here 𝐠ₘ are the sum of the gradient of the variational expectation for each data point
indexed k, projected back to the site vₘ, through the conditional p(fₖ|vₘ)
:param input_data: A tuple of time points and observations</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.loss">
<code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain a <code class="xref any docutils literal notranslate"><span class="pre">Tensor</span></code> representing the loss, which can be used to train the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – A tuple of time points and observations containing the data at which
to calculate the loss for training the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Posterior object to predict outside of the training time points</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.local_objective_and_gradients">
<code class="sig-name descname"><span class="pre">local_objective_and_gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.local_objective_and_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Returs the local_objective and its gradients wrt to the expectation parameters
:param Fmu: means μ […, latent_dim]
:param Fvar: variances σ² […, latent_dim]
:param Y: observations Y […, observation_dim]
:return: local objective and gradient wrt [μ, σ² + μ²]</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.local_objective">
<code class="sig-name descname"><span class="pre">local_objective</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.local_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>local loss in CVI
:param Fmu: means […, latent_dim]
:param Fvar: variances […, latent_dim]
:param Y: observations […, observation_dim]
:return: local objective […]</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.classic_elbo">
<code class="sig-name descname"><span class="pre">classic_elbo</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.classic_elbo" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Computes the ELBO the classic way:</dt><dd><p>ℒ(q) = Σᵢ ∫ log(p(yᵢ | f)) q(f) df - KL[q(f) ‖ p(f)]</p>
</dd>
</dl>
<p>Note: this is mostly for testing purposes and not to be used for optimization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_data</strong> – A tuple of time points and observations</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar tensor representing the ELBO.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.kernel">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">kernel</span></code> &#x2192; <a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the kernel of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.dist_p">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_p</span></code> &#x2192; <a class="reference internal" href="../state_space_model/index.html#markovflow.state_space_model.StateSpaceModel" title="markovflow.state_space_model.StateSpaceModel"><span class="pre">markovflow.state_space_model.StateSpaceModel</span></a><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.dist_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the prior <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><code class="xref any py py-class docutils literal notranslate"><span class="pre">GaussMarkovDistribution</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SparseCVIGaussianProcess.likelihood">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">likelihood</span></code> &#x2192; <span class="pre">gpflow.likelihoods.Likelihood</span><a class="headerlink" href="#markovflow.models.SparseCVIGaussianProcess.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the likelihood of the GP.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.SpatioTemporalSparseVariational">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">SpatioTemporalSparseVariational</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inducing_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_time</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_space</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.kernels.Kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_time</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/spatio_temporal_variational.html#SpatioTemporalSparseVariational"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseVariational" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">SpatioTemporalBase</span></code></p>
<p>Model for Variational Spatio-temporal GP regression using a factor kernel
k_space_time((s,t),(s’,t’)) = k_time(t,t’) * k_space(s,s’)</p>
<p>where k_time is a Markovian kernel.</p>
<blockquote>
<div><p>The following notation is used:
* X=(x,t) - the space-time points of the training data.
* zₛ - the space inducing/pseudo points.
* zₜ - the time inducing/pseudo points.
* y - observations corresponding to points X.
* f(.,.) the spatio-temporal process
* x(.,.) the SSM formulation of the spatio-temporal process
* u(.) = x(zₛ,.) - the spatio-temporal SSM marginalized at zₛ
* p(y | f) - the likelihood
* p(.) the prior distribution
* q(.) the variational distribution</p>
</div></blockquote>
<p>This can be seen as the temporal extension of gpflow.SVGP,
where instead of fixed inducing variables u, they are now time dependent u(t)
and follow a Markov chain.</p>
<p>for a fixed set of spatial inducing inputs zₛ
p(x(zₛ, .)) is a continuous time process of state dimension Mₛd
for a fixed time slice t, p(x(.,t)) ~ GP(0, kₛ)</p>
<p>The following conditional independence holds:
p(x(s,t) | x(zₛ, .)) = p(x(s,t) | s(zₛ, t)), i.e.,
prediction at a new point at time t given x(zₛ, .) only depends on s(zₛ, t)</p>
<p>This builds a spatially sparse process as
q(x(.,.)) = q(x(zₛ, .)) p(x(.,.) <a href="#id1"><span class="problematic" id="id2">|</span></a>x(zₛ, .)),
where the multi-output temporal process q(x(zₛ, .)) is also sparse
q(x(zₛ, .)) = q(x(zₛ, zₜ)) p(x(zₛ,.) <a href="#id3"><span class="problematic" id="id4">|</span></a>x(zₛ,  zₜ))</p>
<p>the marginal q(x(zₛ, zₜ)) is a multivariate Gaussian distribution
parameterized as a state space model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inducing_space</strong> – inducing space points [Ms, D]</p></li>
<li><p><strong>inducing_time</strong> – inducing time points [Mt,]</p></li>
<li><p><strong>kernel_space</strong> – Gpflow space kernel</p></li>
<li><p><strong>kernel_time</strong> – Markovflow time kernel</p></li>
<li><p><strong>likelihood</strong> – a likelihood object</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>num_data</strong> – number of observations</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseVariational.dist_q">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_q</span></code> &#x2192; <a class="reference internal" href="../state_space_model/index.html#markovflow.state_space_model.StateSpaceModel" title="markovflow.state_space_model.StateSpaceModel"><span class="pre">markovflow.state_space_model.StateSpaceModel</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseVariational.dist_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Posterior state space model on inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseVariational.dist_p">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_p</span></code> &#x2192; <a class="reference internal" href="../state_space_model/index.html#markovflow.state_space_model.StateSpaceModel" title="markovflow.state_space_model.StateSpaceModel"><span class="pre">markovflow.state_space_model.StateSpaceModel</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseVariational.dist_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Prior state space model on inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseVariational.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseVariational.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Posterior process</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.SpatioTemporalSparseCVI">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">SpatioTemporalSparseCVI</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inducing_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_time</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_space</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.kernels.Kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_time</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/spatio_temporal_variational.html#SpatioTemporalSparseCVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">SpatioTemporalBase</span></code></p>
<p>Model for Spatio-temporal GP regression using a factor kernel
k_space_time((s,t),(s’,t’)) = k_time(t,t’) * k_space(s,s’)</p>
<p>where k_time is a Markovian kernel.</p>
<blockquote>
<div><p>The following notation is used:
* X=(x,t) - the space-time points of the training data.
* zₛ - the space inducing/pseudo points.
* zₜ - the time inducing/pseudo points.
* y - observations corresponding to points X.
* f(.,.) the spatio-temporal process
* x(.,.) the SSM formulation of the spatio-temporal process
* u(.) = x(zₛ,.) - the spatio-temporal SSM marginalized at zₛ
* p(y | f) - the likelihood
* p(.) the prior distribution
* q(.) the variational distribution</p>
</div></blockquote>
<p>This can be seen as the spatial extension of markovflow’s SparseCVIGaussianProcess
for temporal (only) Gaussian Processes.
The inducing variables u(x,t) are now space and time dependent.</p>
<p>for a fixed set of space points zₛ
p(x(zₛ, .)) is a continuous time process of state dimension Mₛd
for a fixed time slice t, p(x(.,t)) ~ GP(0, kₛ)</p>
<p>The following conditional independence holds:
p(x(s,t) | x(zₛ, .)) = p(x(s,t) | s(zₛ, t)), i.e.,
prediction at a new point at time t given x(zₛ, .) only depends on s(zₛ, t)</p>
<p>This builds a spatially sparse process as
q(x(.,.)) = q(x(zₛ, .)) p(x(.,.) <a href="#id5"><span class="problematic" id="id6">|</span></a>x(zₛ, .)),
where the multi-output temporal process q(x(zₛ, .)) is also sparse
q(x(zₛ, .)) = q(x(zₛ, zₜ)) p(x(zₛ,.) <a href="#id7"><span class="problematic" id="id8">|</span></a>x(zₛ,  zₜ))</p>
<p>the marginal q(x(zₛ, zₜ)) is parameterized as the product
q(x(zₛ, zₜ)) = p(x(zₛ, zₜ)) t(x(zₛ, zₜ))
where p(x(zₛ, zₜ)) is a state space model and t(x(zₛ, zₜ)) are sites.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inducing_space</strong> – inducing space points [Ms, D]</p></li>
<li><p><strong>inducing_time</strong> – inducing time points [Mt,]</p></li>
<li><p><strong>kernel_space</strong> – Gpflow space kernel</p></li>
<li><p><strong>kernel_time</strong> – Markovflow time kernel</p></li>
<li><p><strong>likelihood</strong> – a likelihood object</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>num_data</strong> – The total number of observations.
(relevant when feeding in external minibatches).</p></li>
<li><p><strong>learning_rate</strong> – the learning rate.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Posterior object to predict outside of the training time points</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.dist_q">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_q</span></code> &#x2192; <a class="reference internal" href="../state_space_model/index.html#markovflow.state_space_model.StateSpaceModel" title="markovflow.state_space_model.StateSpaceModel"><span class="pre">markovflow.state_space_model.StateSpaceModel</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.dist_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the variational posterior distribution on the vector of inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.dist_p">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_p</span></code> &#x2192; <a class="reference internal" href="../state_space_model/index.html#markovflow.state_space_model.StateSpaceModel" title="markovflow.state_space_model.StateSpaceModel"><span class="pre">markovflow.state_space_model.StateSpaceModel</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.dist_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the prior distribution on the vector of inducing states</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.projection_inducing_states_to_observations">
<code class="sig-name descname"><span class="pre">projection_inducing_states_to_observations</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.projection_inducing_states_to_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the projection matrix from of the conditional mean of f(x,t) | s(t)
:param input_data: Time point and associated spatial dimension to generate observations for,</p>
<blockquote>
<div><p>with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[space_dim</span> <span class="pre">+</span> <span class="pre">1,</span> <span class="pre">num_time_points]</span></code>.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The projection matrix with shape [num_time_points, obs_dim, num_inducing_time x state_dim ]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.update_sites">
<code class="sig-name descname"><span class="pre">update_sites</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.10)"><span class="pre">None</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.update_sites" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Perform one joint update of the Gaussian sites</dt><dd><p>𝜽ₘ ← ρ𝜽ₘ + (1-ρ)𝐠ₘ</p>
</dd>
</dl>
<p>Here 𝐠ₘ are the sum of the gradient of the variational expectation for each data point
indexed k, projected back to the site vₘ = [uₘ, uₘ₊₁], through the conditional p(fₖ|vₘ)
:param input_data: A tuple of time points and observations</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.local_objective_and_gradients">
<code class="sig-name descname"><span class="pre">local_objective_and_gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.local_objective_and_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Returs the local_objective and its gradients wrt to the expectation parameters
:param Fmu: means μ […, latent_dim]
:param Fvar: variances σ² […, latent_dim]
:param Y: observations Y […, observation_dim]
:return: local objective and gradient wrt [μ, σ² + μ²]</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.SpatioTemporalSparseCVI.local_objective">
<code class="sig-name descname"><span class="pre">local_objective</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.SpatioTemporalSparseCVI.local_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>local loss in CVI
:param Fmu: means […, latent_dim]
:param Fvar: variances […, latent_dim]
:param Y: observations […, observation_dim]
:return: local objective […]</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.VariationalGaussianProcess">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">VariationalGaussianProcess</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_distribution</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/variational.html#VariationalGaussianProcess"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="models/index.html#markovflow.models.models.MarkovFlowModel" title="markovflow.models.models.MarkovFlowModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">markovflow.models.models.MarkovFlowModel</span></code></a></p>
<p>Approximates a <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">GaussMarkovDistribution</span></code></a>
with a general likelihood using a Gaussian posterior.</p>
<p>The following notation is used:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> - the time points of the training data</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> - observations corresponding to time points <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(s(.)\)</span> - the latent state of the Markov chain</p></li>
<li><p><span class="math notranslate nohighlight">\(f(.)\)</span> - the noise free predictions of the model</p></li>
<li><p><span class="math notranslate nohighlight">\(p(y | f)\)</span> - the likelihood</p></li>
<li><p><span class="math notranslate nohighlight">\(p(.)\)</span> - the true distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(q(.)\)</span> - the variational distribution</p></li>
</ul>
</div></blockquote>
<p>Subscript is used to denote dependence for notational convenience,
for example <span class="math notranslate nohighlight">\(fₖ === f(k)\)</span>.</p>
<p>With a prior generative model comprising a Gauss-Markov distribution, an emission model and an
arbitrary likelihood on the emitted variables, these define:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p(xₖ₊₁| xₖ)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(fₖ = H xₖ\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p(yₖ | fₖ)\)</span></p></li>
</ul>
</div></blockquote>
<p>We would like to approximate the posterior of this generative model with a parametric
model <span class="math notranslate nohighlight">\(q\)</span>, comprising of the same distribution as the prior.</p>
<p>To approximate the posterior, we maximise the evidence lower bound (ELBO) <span class="math notranslate nohighlight">\(ℒ\)</span> with
respect to the parameters of the variational distribution, since:</p>
<div class="math notranslate nohighlight">
\[log p(y) = ℒ(q) + KL[q ‖ p(f | y)]\]</div>
<p>…where:</p>
<div class="math notranslate nohighlight">
\[ℒ(q) = ∫ log(p(f, y) / q(f)) q(f) df\]</div>
<p>Since the last term is non-negative, the ELBO provides a lower bound to the log-likelihood of
the model. This bound is exact when <span class="math notranslate nohighlight">\(KL[q ‖ p(f | y)] = 0\)</span>; that is, our approximation is
sufficiently flexible to capture the true posterior.</p>
<p>This turns the inference into an optimisation problem: find the optional <span class="math notranslate nohighlight">\(q\)</span>.</p>
<p>To calculate the ELBO, we rewrite it as:</p>
<div class="math notranslate nohighlight">
\[ℒ(q) = Σᵢ ∫ log(p(yᵢ | f)) q(f) df - KL[q(f) ‖ p(f)]\]</div>
<p>The first term is the ‘variational expectation’ of the model likelihood;
the second is the KL from the prior to the approximation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> – A tuple of <code class="docutils literal notranslate"><span class="pre">(time_points,</span> <span class="pre">observations)</span></code> containing the observed data:
time points of observations, with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p></li>
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>likelihood</strong> – A likelihood.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>initial_distribution</strong> – An initial configuration for the variational distribution,
with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.elbo">
<code class="sig-name descname"><span class="pre">elbo</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.elbo" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the evidence lower bound (ELBO) <span class="math notranslate nohighlight">\(log p(y)\)</span>. We rewrite the ELBO as:</p>
<div class="math notranslate nohighlight">
\[ℒ(q(x)) = Σᵢ ∫ log(p(yᵢ | fₓ)) q(fₓ) df - KL[q(sₓ) ‖ p(sₓ)]\]</div>
<p>The first term is the ‘variational expectation’ (VE); the second is the KL divergence from
the prior to the approximation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A scalar tensor (summed over the batch_shape dimension) representing the ELBO.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.time_points">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">time_points</span></code> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.time_points" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the time points of our observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.observations">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">observations</span></code> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.kernel">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">kernel</span></code> &#x2192; <a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the kernel of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.likelihood">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">likelihood</span></code> &#x2192; <span class="pre">gpflow.likelihoods.Likelihood</span><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the likelihood of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.mean_function">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">mean_function</span></code> &#x2192; <a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.mean_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the mean function of the GP.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.dist_p">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_p</span></code> &#x2192; <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.dist_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the prior Gauss-Markov distribution.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.dist_q">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dist_q</span></code> &#x2192; <a class="reference internal" href="../gauss_markov/index.html#markovflow.gauss_markov.GaussMarkovDistribution" title="markovflow.gauss_markov.GaussMarkovDistribution"><span class="pre">markovflow.gauss_markov.GaussMarkovDistribution</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.dist_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the variational distribution as a Gauss-Markov distribution.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.posterior">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">posterior</span></code> &#x2192; <a class="reference internal" href="../posterior/index.html#markovflow.posterior.PosteriorProcess" title="markovflow.posterior.PosteriorProcess"><span class="pre">markovflow.posterior.PosteriorProcess</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain a posterior process for inference.</p>
<p>For this class this is the <a class="reference internal" href="../posterior/index.html#markovflow.posterior.AnalyticPosteriorProcess" title="markovflow.posterior.AnalyticPosteriorProcess"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticPosteriorProcess</span></code></a>
built from the variational distribution. This will be a locally optimal variational
approximation of the posterior after optimisation.</p>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.VariationalGaussianProcess.loss">
<code class="sig-name descname"><span class="pre">loss</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.VariationalGaussianProcess.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the loss, which is the negative ELBO.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="markovflow.models.CVIGaussianProcess">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">CVIGaussianProcess</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="../kernels/index.html#markovflow.kernels.SDEKernel" title="markovflow.kernels.SDEKernel"><span class="pre">markovflow.kernels.SDEKernel</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../mean_function/index.html#markovflow.mean_function.MeanFunction" title="markovflow.mean_function.MeanFunction"><span class="pre">markovflow.mean_function.MeanFunction</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/markovflow/models/variational_cvi.html#CVIGaussianProcess"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">GaussianProcessWithSitesBase</span></code></p>
<p>Provides an alternative parameterization to a
<a class="reference internal" href="variational/index.html#markovflow.models.variational.VariationalGaussianProcess" title="markovflow.models.variational.VariationalGaussianProcess"><code class="xref py py-class docutils literal notranslate"><span class="pre">VariationalGaussianProcess</span></code></a>.</p>
<p>This class approximates the posterior of a model with a GP prior and a general likelihood
using a Gaussian posterior parameterized with Gaussian sites.</p>
<p>The following notation is used:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> - the time points of the training data</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> - observations corresponding to time points <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(s(.)\)</span> - the latent state of the Markov chain</p></li>
<li><p><span class="math notranslate nohighlight">\(f(.)\)</span> - the noise free predictions of the model</p></li>
<li><p><span class="math notranslate nohighlight">\(p(y | f)\)</span> - the likelihood</p></li>
<li><p><span class="math notranslate nohighlight">\(t(f)\)</span> - a site (indices will refer to the associated data point)</p></li>
<li><p><span class="math notranslate nohighlight">\(p(.)\)</span> the prior distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(q(.)\)</span> the variational distribution</p></li>
</ul>
</div></blockquote>
<p>We use the state space formulation of Markovian Gaussian Processes that specifies:</p>
<ul class="simple">
<li><p>The conditional density of neighbouring latent states <span class="math notranslate nohighlight">\(p(sₖ₊₁| sₖ)\)</span></p></li>
<li><p>How to read out the latent process from these states <span class="math notranslate nohighlight">\(fₖ = H sₖ\)</span></p></li>
</ul>
<p>The likelihood links data to the latent process and <span class="math notranslate nohighlight">\(p(yₖ | fₖ)\)</span>.
We would like to approximate the posterior over the latent state space model of this model.</p>
<p>To approximate the posterior, we maximise the evidence lower bound (ELBO) <span class="math notranslate nohighlight">\(ℒ\)</span> with
respect to the parameters of the variational distribution, since:</p>
<div class="math notranslate nohighlight">
\[log p(y) = ℒ(q) + KL[q(s) ‖ p(s | y)]\]</div>
<p>…where:</p>
<div class="math notranslate nohighlight">
\[ℒ(q) = ∫ log(p(s, y) / q(s)) q(s) ds\]</div>
<p>We parameterize the variational posterior through sites <span class="math notranslate nohighlight">\(tₖ(fₖ)\)</span>:</p>
<div class="math notranslate nohighlight">
\[q(s) = p(s) ∏ₖ tₖ(fₖ)\]</div>
<p>…where <span class="math notranslate nohighlight">\(tₖ(fₖ)\)</span> are univariate Gaussian sites parameterized in the natural form:</p>
<div class="math notranslate nohighlight">
\[t(f) = exp(𝜽ᵀφ(f) - A(𝜽))\]</div>
<p>…and where <span class="math notranslate nohighlight">\(𝜽=[θ₁,θ₂]\)</span> and <span class="math notranslate nohighlight">\(𝛗(f)=[f,f²]\)</span>.</p>
<p>Here, <span class="math notranslate nohighlight">\(𝛗(f)\)</span> are the sufficient statistics and <span class="math notranslate nohighlight">\(𝜽\)</span> are the natural parameters.
Note that the subscript <span class="math notranslate nohighlight">\(k\)</span> has been omitted for simplicity.</p>
<p>The natural gradient update of the sites can be shown to be the gradient of the
variational expectations:</p>
<div class="math notranslate nohighlight">
\[𝐠 = ∇[𝞰][∫ log(p(y=Y|f)) q(f) df]\]</div>
<p>…with respect to the expectation parameters:</p>
<div class="math notranslate nohighlight">
\[𝞰 = E[𝛗(f)] = [μ, σ² + μ²]\]</div>
<p>That is, <span class="math notranslate nohighlight">\(𝜽 ← ρ𝜽 + (1-ρ)𝐠\)</span>, where <span class="math notranslate nohighlight">\(ρ\)</span> is the learning rate.</p>
<p>The key reference is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">khan2017conjugate</span><span class="p">,</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Conjugate</span><span class="o">-</span><span class="n">Computation</span> <span class="n">Variational</span> <span class="n">Inference</span><span class="p">:</span> <span class="n">Converting</span> <span class="n">Variational</span> <span class="n">Inference</span>
         <span class="ow">in</span> <span class="n">Non</span><span class="o">-</span><span class="n">Conjugate</span> <span class="n">Models</span> <span class="n">to</span> <span class="n">Inferences</span> <span class="ow">in</span> <span class="n">Conjugate</span> <span class="n">Models</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Khan</span><span class="p">,</span> <span class="n">Mohammad</span> <span class="ow">and</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">Wu</span><span class="p">},</span>
  <span class="n">booktitle</span><span class="o">=</span><span class="p">{</span><span class="n">Artificial</span> <span class="n">Intelligence</span> <span class="ow">and</span> <span class="n">Statistics</span><span class="p">},</span>
  <span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">878</span><span class="o">--</span><span class="mi">887</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2017</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> – <p>A tuple containing the observed data:</p>
<ul>
<li><p>Time points of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code></p></li>
<li><p>Observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code></p></li>
</ul>
</p></li>
<li><p><strong>kernel</strong> – A kernel that defines a prior over functions.</p></li>
<li><p><strong>likelihood</strong> – A likelihood with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_inducing]</span></code>.</p></li>
<li><p><strong>mean_function</strong> – The mean function for the GP. Defaults to no mean function.</p></li>
<li><p><strong>learning_rate</strong> – The learning rate of the algorithm.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="markovflow.models.CVIGaussianProcess.local_objective">
<code class="sig-name descname"><span class="pre">local_objective</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess.local_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate local loss in CVI.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Fmu</strong> – Means with shape <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">latent_dim]</span></code>.</p></li>
<li><p><strong>Fvar</strong> – Variances with shape <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">latent_dim]</span></code>.</p></li>
<li><p><strong>Y</strong> – Observations with shape <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">observation_dim]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A local objective with shape <code class="docutils literal notranslate"><span class="pre">[...]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.CVIGaussianProcess.local_objective_and_gradients">
<code class="sig-name descname"><span class="pre">local_objective_and_gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Fmu</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">Fvar</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess.local_objective_and_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the local objective and its gradients with regard to the expectation parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Fmu</strong> – Means <span class="math notranslate nohighlight">\(μ\)</span> with shape <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">latent_dim]</span></code>.</p></li>
<li><p><strong>Fvar</strong> – Variances <span class="math notranslate nohighlight">\(σ²\)</span> with shape <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">latent_dim]</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A local objective and gradient with regard to <span class="math notranslate nohighlight">\([μ, σ² + μ²]\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.CVIGaussianProcess.update_sites">
<code class="sig-name descname"><span class="pre">update_sites</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.10)"><span class="pre">None</span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess.update_sites" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform one joint update of the Gaussian sites. That is:</p>
<div class="math notranslate nohighlight">
\[𝜽 ← ρ𝜽 + (1-ρ)𝐠\]</div>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.CVIGaussianProcess.elbo">
<code class="sig-name descname"><span class="pre">elbo</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess.elbo" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the evidence lower bound (ELBO) <span class="math notranslate nohighlight">\(log p(y)\)</span>.</p>
<p>This is done by computing the marginal of the model in which the likelihood terms were
replaced by the Gaussian sites.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A scalar tensor representing the ELBO.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.CVIGaussianProcess.classic_elbo">
<code class="sig-name descname"><span class="pre">classic_elbo</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess.classic_elbo" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the ELBO the classic way. That is:</p>
<div class="math notranslate nohighlight">
\[ℒ(q) = Σᵢ ∫ log(p(yᵢ | f)) q(f) df - KL[q(f) ‖ p(f)]\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is mostly for testing purposes and should not be used for optimization.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A scalar tensor representing the ELBO.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="markovflow.models.CVIGaussianProcess.predict_log_density">
<code class="sig-name descname"><span class="pre">predict_log_density</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><a class="headerlink" href="#markovflow.models.CVIGaussianProcess.predict_log_density" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log density of the data at the new data points.
:param input_data: A tuple of time points and observations containing the data at which</p>
<blockquote>
<div><p>to calculate the loss for training the model:
a tensor of inputs with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data]</span></code>,
a tensor of observations with shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">[num_data,</span> <span class="pre">observation_dim]</span></code>.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>full_output_cov</strong> – Either full output covariance (<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or marginal
variances (<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.10)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright Copyright 2021 The markovflow Contributors

Licensed under the Apache License, Version 2.0
.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>