
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Basic classification using the VGP model &#8212; markovflow 0.1.0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/pydata-custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Basic classification using the PEP model" href="markovflow_pep.html" />
    <link rel="prev" title="Choosing and combining kernels" href="choosing_and_combining_kernels.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <img src="../_static/logo.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">Markovflow</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../tutorials.html">Tutorials</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../autoapi/markovflow/index.html">API Reference</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/secondmind-labs/markovflow" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
          
            
                <li class="">
                    <a href="markovflow_gpr.html">Basic regression using the GPR model</a>
                </li>
            
          
            
                <li class="">
                    <a href="choosing_and_combining_kernels.html">Choosing and combining kernels</a>
                </li>
            
          
            
                <li class="active">
                    <a href="">Basic classification using the VGP model</a>
                </li>
            
          
            
                <li class="">
                    <a href="markovflow_pep.html">Basic classification using the PEP model</a>
                </li>
            
          
            
                <li class="">
                    <a href="markovflow_cvi.html">Basic classification using the CVIGaussianProcess model</a>
                </li>
            
          
            
                <li class="">
                    <a href="markovflow_sparse_pep.html">Basic classification using the SPEP model</a>
                </li>
            
          
            
                <li class="">
                    <a href="markovflow_sparse_cvi.html">Basic classification using the SparseCVIGaussianProcess model</a>
                </li>
            
          
            
                <li class="">
                    <a href="importance_weighted_vi.html">Classification using importance-weighted SGPR</a>
                </li>
            
          
            
                <li class="">
                    <a href="factor_analysis.html">Factor Analysis</a>
                </li>
            
          
            
                <li class="">
                    <a href="stacked_kernels.html">Stacked kernels and multiple outputs</a>
                </li>
            
          
            
                <li class="">
                    <a href="piecewise_kernels.html">Regression using a piecewise kernel</a>
                </li>
            
          
            
                <li class="">
                    <a href="multistage_likelihood.html">Demo of MultiStageLikelihood with plain SVGP model</a>
                </li>
            
          
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-1:-Generate-training-data" class="nav-link">Step 1: Generate training data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-2:-Choose-a-kernel" class="nav-link">Step 2: Choose a kernel</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-3:-Build-and-optimise-a-model" class="nav-link">Step 3: Build and optimise a model</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#Markflow-implementation-notes" class="nav-link">Markflow implementation notes</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-4:-Generate-a-(posterior)-mean-for-the-training-data" class="nav-link">Step 4: Generate a (posterior) mean for the training data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-5:-Make-a-prediction-for-the-future" class="nav-link">Step 5: Make a prediction for the future</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-6:-Show-a-history-of-confidence" class="nav-link">Step 6: Show a history of confidence</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-7:-Generate-sample-trajectories" class="nav-link">Step 7: Generate sample trajectories</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#Step-8:-Observe-more-data-in-the-future,-and-update-the-model" class="nav-link">Step 8: Observe more data in the future, and update the model</a>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Basic-classification-using-the-VGP-model">
<h1>Basic classification using the VGP model<a class="headerlink" href="#Basic-classification-using-the-VGP-model" title="Permalink to this headline">Â¶</a></h1>
<p>This notebook explains how to use Markovflow to build and optimise a variational GP regression model (VGP) for a time series. Here, we perform binary classification with time as the input.</p>
<p>As with GPR, the observations do not have to be regularly spaced. However, they do need to be sequential. We denote the input/output tuples as <span class="math notranslate nohighlight">\((x_i, y_i)_{1 \leq i \leq n}\)</span>, where <span class="math notranslate nohighlight">\(x_i\)</span> is a scalar value and <span class="math notranslate nohighlight">\(y_i \in \{0, 1\}\)</span>.</p>
<p>Our probabilistic model for this data is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
f \sim \mathcal{GP}(0, k(., .)) \\
y_i \sim \mathcal{B}(\Phi(f(x_i)))
\end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Phi\)</span> is a function that maps <span class="math notranslate nohighlight">\(f(x_i)\)</span> to <span class="math notranslate nohighlight">\([0, 1]\)</span>, the probability that <span class="math notranslate nohighlight">\(y_i=1\)</span>. In practice, we choose <span class="math notranslate nohighlight">\(\Phi\)</span> to be the standard normal cumulative distribution function (also known as the probit function) which maps to <span class="math notranslate nohighlight">\([0, 1]\)</span>.</p>
<p><strong>NOTE:</strong> If you have difficulty running this notebook, consider clearing the output and then restarting the kernel.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Setup</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Turn off warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">gpflow</span>

<span class="kn">from</span> <span class="nn">gpflow</span> <span class="kn">import</span> <span class="n">default_float</span><span class="p">,</span> <span class="n">set_trainable</span>
<span class="kn">from</span> <span class="nn">gpflow.ci_utils</span> <span class="kn">import</span> <span class="n">ci_niter</span>
<span class="kn">from</span> <span class="nn">gpflow.likelihoods</span> <span class="kn">import</span> <span class="n">Bernoulli</span>

<span class="kn">from</span> <span class="nn">markovflow.models.variational</span> <span class="kn">import</span> <span class="n">VariationalGaussianProcess</span>
<span class="kn">from</span> <span class="nn">markovflow.kernels</span> <span class="kn">import</span> <span class="n">Matern12</span><span class="p">,</span> <span class="n">Product</span><span class="p">,</span> <span class="n">HarmonicOscillator</span>


<span class="n">FLOAT_TYPE</span> <span class="o">=</span> <span class="n">default_float</span><span class="p">()</span>

<span class="c1"># uncomment in notebook</span>
<span class="c1"># try:</span>
<span class="c1">#     from IPython import get_ipython</span>
<span class="c1">#     get_ipython().run_line_magic(&#39;matplotlib&#39;, &#39;inline&#39;)</span>
<span class="c1"># except AttributeError:</span>
<span class="c1">#     print(&#39;Magic function can only be used in IPython environment&#39;)</span>
<span class="c1">#     matplotlib.use(&#39;Agg&#39;)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-09-17 15:49:43.962455: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-09-17 15:49:43.962494: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div></div>
</div>
<div class="section" id="Step-1:-Generate-training-data">
<h2>Step 1: Generate training data<a class="headerlink" href="#Step-1:-Generate-training-data" title="Permalink to this headline">Â¶</a></h2>
<p>First, letâ€™s generate some binary data <span class="math notranslate nohighlight">\(X = (x_1, \dots, x_n)\)</span> and <span class="math notranslate nohighlight">\(Y = (y_1, \dots, y_n)^T\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">create_binary_observations</span><span class="p">(</span><span class="n">time_points</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A helper function to create training data.</span>
<span class="sd">    :param time_points: Time points to generate observations for.</span>
<span class="sd">    :return: Tuple[x,y] Data that represents the observations&#39; shapes:</span>
<span class="sd">        X = [num_points, 1],</span>
<span class="sd">        Y = [num_points, state_dim , 1] where state_dim is currently 1</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">period</span> <span class="o">=</span> <span class="mf">12.</span>
    <span class="n">observations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">12</span> <span class="o">*</span> <span class="n">time_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
    <span class="c1"># Add some noise</span>
    <span class="n">observations</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time_points</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">.3</span>

    <span class="n">logic</span> <span class="o">=</span> <span class="p">(</span><span class="n">observations</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">binary</span> <span class="o">=</span> <span class="p">(</span><span class="n">logic</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">time_points</span><span class="p">,</span> <span class="n">binary</span>

<span class="c1"># Generate some observations</span>
<span class="n">time_points</span><span class="p">,</span> <span class="n">observations</span> <span class="o">=</span> <span class="n">create_binary_observations</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">))</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_points</span><span class="p">,</span> <span class="n">observations</span><span class="p">,</span> <span class="s1">&#39;C0x&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;Label&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_markovflow_variational_gpr_4_1.png" src="../_images/notebooks_markovflow_variational_gpr_4_1.png" />
</div>
</div>
</div>
<div class="section" id="Step-2:-Choose-a-kernel">
<h2>Step 2: Choose a kernel<a class="headerlink" href="#Step-2:-Choose-a-kernel" title="Permalink to this headline">Â¶</a></h2>
<p>To build a model we need a Markovian kernel, that is, one that has an equivalent Stochastic Differential Equation (SDE) representation. The SDE framework covers a large variety of well-known kernels and precisions.</p>
<p>You can combine these kernels by taking their sums or products.</p>
<p>In this case, we notice that the data looks roughly periodic, so we combine the Matern12 and periodic kernels using the product kernel.</p>
<p><strong>NOTE:</strong> Avoid any Sum combinations that use periodic kernels, because these will fail (for example, <code class="docutils literal notranslate"><span class="pre">Sum(periodic,any</span> <span class="pre">other</span> <span class="pre">kernel)</span></code>.</p>
<p><strong>NOTE:</strong> Choosing a higher-order Matern kernel for VGPs using the Markovflow SDE representation could result in over-parameterisation (resulting in Cholesky errors).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">period</span> <span class="o">=</span> <span class="mf">10.0</span>
<span class="n">periodic_kernel</span> <span class="o">=</span> <span class="n">HarmonicOscillator</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="n">period</span><span class="p">)</span>
<span class="n">matern_kernel</span> <span class="o">=</span> <span class="n">Matern12</span><span class="p">(</span><span class="n">lengthscale</span><span class="o">=</span><span class="mf">6.</span> <span class="o">*</span> <span class="n">period</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># Because we are multiplying them together, we need to train only one kernel variance parameter</span>
<span class="n">set_trainable</span><span class="p">(</span><span class="n">matern_kernel</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">Product</span><span class="p">([</span><span class="n">matern_kernel</span><span class="p">,</span> <span class="n">periodic_kernel</span><span class="p">])</span>

<span class="c1"># We see Matern12 has only two dimensions (therefore there is less risk of overparameterising)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">state_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-09-17 15:49:45.583757: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-17 15:49:45.583965: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-09-17 15:49:45.583976: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-17 15:49:45.583994: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az178-774): /proc/driver/nvidia/version does not exist
2022-09-17 15:49:45.584241: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-17 15:49:45.584351: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-09-17 15:49:45.598663: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
</pre></div></div>
</div>
</div>
<div class="section" id="Step-3:-Build-and-optimise-a-model">
<h2>Step 3: Build and optimise a model<a class="headerlink" href="#Step-3:-Build-and-optimise-a-model" title="Permalink to this headline">Â¶</a></h2>
<p>This is a classification problem with outputs between <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code>, so we create a variational GP model using a Bernoulli likelihood.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create a likelihood object</span>
<span class="n">bernoulli_likelihood</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">()</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">time_points</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">observations</span><span class="p">))</span>
<span class="n">vgpc</span> <span class="o">=</span> <span class="n">VariationalGaussianProcess</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
                                  <span class="n">likelihood</span><span class="o">=</span><span class="n">bernoulli_likelihood</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /home/runner/work/markovflow/markovflow/.venv/lib/python3.7/site-packages/tensorflow/python/ops/linalg/linear_operator_kronecker.py:224: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.
Instructions for updating:
Do not call `graph_parents`.
</pre></div></div>
</div>
<p>(<strong>NOTE:</strong> The following comments are true for training VGPs in general, and are not unique to Markovflow.)</p>
<p>Recall that when applying the GPR model in the regression context, we sought to maximise the marginal likelihood with respect to the hyperparameters (that is, the kernel parameters and the likelihood variance).</p>
<p>Unlike traditional GPR, the posterior on ğ‘“ given the data is not Gaussian anymore, and there is no closed form expression for it. Instead, we use variational inference to find the Gaussian distribution that gives the best approximation to the true posterior in terms of the Kullback-Leibler (KL) divergence. KL divergence quantifies how different two probability distributions are.</p>
<p>To do this, maximise the Evidence Lower Bound (ELBO) using a form of gradient-based optimisation such as gradient descent or Adam. Maximising the ELBO is equivalent to minimising the KL divergence. The intention is to make our posterior approximation as close as possible to the true posterior.</p>
<p>As such, there are two training phases required for VGPR: firstly, we adjust the (Gaussian) parameters for our posterior approximation, and secondly, we adjust the hyperparameters (as in traditional GPR).</p>
<p>The theoretically correct, precise way to conduct both steps would be to optimise phase 1 until convergence, then perform a small optimisation step for phase 2 and repeat. However, jointly optimising the variational parameters and the hyperparameters works well in practice and is faster.</p>
<p>In practice, we take single steps for phase 1 and 2, and then repeat. Often this approach works well enough and converges much faster than the precise approach mentioned previously.</p>
<div class="section" id="Markflow-implementation-notes">
<h3>Markflow implementation notes<a class="headerlink" href="#Markflow-implementation-notes" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>Markovflow combines both training phases, so it appears in the following example as a single optimisation step.</p></li>
<li><p>Markovflow models often share common interfaces, including a loss method to train on, so here we are minimising a loss value (which is equivalent to maximising ELBO).</p></li>
<li><p>If you encounter â€˜Banded Cholesky decomposition failureâ€™ errors during training, it <em>could</em> be indicative of poor input scaling, hyperparameter misspecification, or overly aggressive optimisation (that is, the learning rate is too large).</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># equivalent to loss = -vgpc.elbo()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">()</span>

<span class="c1"># Before optimisation, calculate the loss of the observations given the current kernel parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss before optimisation: &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loss before optimisation:  31.18199464278479
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Start at a small learning rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="n">ci_niter</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">opt_step</span><span class="p">():</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">vgpc</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">opt_step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="se">\t</span><span class="s2">Loss: </span><span class="si">{</span><span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss after optimisation: </span><span class="si">{</span><span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Save our trained hyperparamters (these will be used in Step 8)</span>
<span class="n">saved_hyperparams</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">trainable_variables</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /home/runner/work/markovflow/markovflow/.venv/lib/python3.7/site-packages/tensorflow/python/ops/linalg/linear_operator_full_matrix.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.
Instructions for updating:
Do not pass `graph_parents`.  They will  no longer be used.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-09-17 15:49:52.622775: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-09-17 15:49:52.673075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2793435000 Hz
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Iteration: 0    Loss: 30.64525364181372
Iteration: 500  Loss: 11.041065961553501
Iteration: 1000 Loss: 9.239665802444875
Iteration: 1500 Loss: 8.339189503986535
Loss after optimisation: 7.768689351743879
</pre></div></div>
</div>
<p>We can see how our kernel parameters have changed from our initial values.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">vgpc</span><span class="o">.</span><span class="n">_kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ name                             â”‚ class     â”‚ transform   â”‚ prior   â”‚ trainable   â”‚ shape   â”‚ dtype   â”‚ value              â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ Product._kernels[0]._state_mean  â”‚ Parameter â”‚ Identity    â”‚         â”‚ False       â”‚ (1,)    â”‚ float64 â”‚ [0.]               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Product._kernels[0]._lengthscale â”‚ Parameter â”‚ Softplus    â”‚         â”‚ True        â”‚ ()      â”‚ float64 â”‚ 59.410814670763195 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Product._kernels[0]._variance    â”‚ Parameter â”‚ Softplus    â”‚         â”‚ False       â”‚ ()      â”‚ float64 â”‚ 1.0                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Product._kernels[1]._state_mean  â”‚ Parameter â”‚ Identity    â”‚         â”‚ False       â”‚ (2,)    â”‚ float64 â”‚ [0. 0.]            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Product._kernels[1]._variance    â”‚ Parameter â”‚ Softplus    â”‚         â”‚ True        â”‚ ()      â”‚ float64 â”‚ 2.758784207544615  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Product._kernels[1]._period      â”‚ Parameter â”‚ Softplus    â”‚         â”‚ True        â”‚ ()      â”‚ float64 â”‚ 10.455321373916806 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Product._state_mean              â”‚ Parameter â”‚ Identity    â”‚         â”‚ False       â”‚ (2,)    â”‚ float64 â”‚ [0. 0.]            â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Step-4:-Generate-a-(posterior)-mean-for-the-training-data">
<h2>Step 4: Generate a (posterior) mean for the training data<a class="headerlink" href="#Step-4:-Generate-a-(posterior)-mean-for-the-training-data" title="Permalink to this headline">Â¶</a></h2>
<p>As with GPR, we can get the posterior means of the true function values without observation noise. This is less applicable in a classification scenario, but could be useful in other VGPR applications.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">vgpc.posterior.predict_y</span></code> to get the posterior of the latent function at the future times that we want to predict.</p>
<p>We then pass these latent predictions through our function <span class="math notranslate nohighlight">\(\Phi\)</span> (this effectively squashes our latent function values to between <span class="math notranslate nohighlight">\([0,1]\)</span>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Obtain means and covariances for latent predictions</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">vgpc</span><span class="o">.</span><span class="n">posterior</span>

<span class="n">latent_mean</span><span class="p">,</span> <span class="n">latent_var</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">time_points</span><span class="p">))</span>

<span class="c1"># Define our function $\Phi$</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">erf</span>


<span class="k">def</span> <span class="nf">Phi</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  <span class="c1"># NumPy version of the inv_probit</span>
    <span class="n">jitter</span> <span class="o">=</span> <span class="mf">1e-3</span>  <span class="c1"># Ensures that the output is strictly between 0 and 1</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">erf</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)))</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">jitter</span><span class="p">)</span> <span class="o">+</span> <span class="n">jitter</span>


<span class="c1"># Plot the results</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">Phi</span><span class="p">(</span><span class="n">latent_mean</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_points</span><span class="p">,</span> <span class="n">latent_mean</span><span class="p">,</span> <span class="s1">&#39;C0*&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_markovflow_variational_gpr_15_0.png" src="../_images/notebooks_markovflow_variational_gpr_15_0.png" />
</div>
</div>
</div>
<div class="section" id="Step-5:-Make-a-prediction-for-the-future">
<h2>Step 5: Make a prediction for the future<a class="headerlink" href="#Step-5:-Make-a-prediction-for-the-future" title="Permalink to this headline">Â¶</a></h2>
<p>We use <code class="docutils literal notranslate"><span class="pre">vgpc.posterior.predict_f</span></code> to get the posterior of the latent function at the future times that we want to predict.</p>
<p>Then, similar to Step 4, we pass these latent predictions through our function <span class="math notranslate nohighlight">\(\Phi\)</span>.</p>
<p>Letâ€™s start by predicting what class we forecast to occur at <code class="docutils literal notranslate"><span class="pre">t=33</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create a new observation for us to evaluate the prediction</span>
<span class="n">new_time_to_predict</span><span class="p">,</span> <span class="n">actual_val_for_new_time</span> <span class="o">=</span> <span class="n">create_binary_observations</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">33.</span><span class="p">]))</span>

<span class="c1"># Obtain latent predictions from our GP</span>
<span class="n">latent_predicted_mean_future_single</span><span class="p">,</span> <span class="n">latent_predicted_cov_future_single</span> <span class="o">=</span> \
    <span class="n">pred</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_time_to_predict</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_TYPE</span><span class="p">))</span>

<span class="c1"># Map these latent predictions through the inverse link function Î¦</span>
<span class="n">predicted_mean_future_single</span> <span class="o">=</span> <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean_future_single</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Predicted value&quot;</span><span class="p">,</span> <span class="n">predicted_mean_future_single</span><span class="p">,</span> <span class="s2">&quot;  Actual value&quot;</span><span class="p">,</span> <span class="n">actual_val_for_new_time</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Predicted value [[0.18021729]]   Actual value [[0]]
</pre></div></div>
</div>
<p>Now letâ€™s forecast the mean trajectory over time. <strong>NOTE:</strong> As we move further away from known values, our uncertainly increases, and our forecasted mean values revert back to the prior (that is, zero mean).</p>
<p>When you plot the data, the black cross corresponds to the forecasted value, and the red star corresponds to the true value.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Generate some time points in the future</span>
<span class="n">future_time_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">time_points</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">time_points</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Obtain latent predictions from our GP</span>
<span class="n">latent_predicted_mean_future</span><span class="p">,</span> <span class="n">latent_predicted_cov_future</span> <span class="o">=</span> \
    <span class="n">pred</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">future_time_points</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_TYPE</span><span class="p">))</span>

<span class="c1"># Map these latent predictions through the inverse link function Î¦</span>
<span class="n">predicted_mean_future</span> <span class="o">=</span> <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean_future</span><span class="p">)</span>

<span class="c1"># Plot the means and covariances for these future time points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">future_time_points</span><span class="p">,</span> <span class="n">predicted_mean_future</span><span class="p">,</span> <span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">future_time_points</span><span class="p">,</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean_future</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                     <span class="n">latent_predicted_cov_future</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])),</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean_future</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                     <span class="n">latent_predicted_cov_future</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])),</span>
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_time_to_predict</span><span class="p">,</span> <span class="n">actual_val_for_new_time</span><span class="p">,</span> <span class="s1">&#39;r*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_time_to_predict</span><span class="p">,</span> <span class="n">predicted_mean_future_single</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_points</span><span class="p">,</span> <span class="n">observations</span><span class="p">,</span> <span class="s1">&#39;C0x&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_markovflow_variational_gpr_19_0.png" src="../_images/notebooks_markovflow_variational_gpr_19_0.png" />
</div>
</div>
</div>
<div class="section" id="Step-6:-Show-a-history-of-confidence">
<h2>Step 6: Show a history of confidence<a class="headerlink" href="#Step-6:-Show-a-history-of-confidence" title="Permalink to this headline">Â¶</a></h2>
<p>We can use the same trained VGP and fill in the unknown or unobserved points from the past to estimate how likely it is that we would have observed one class or another.</p>
<p>This is achieved by the <code class="docutils literal notranslate"><span class="pre">vgpc.posterior.predict_f</span></code> method.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Generate some other time points to evaluate</span>
<span class="n">intermediate_time_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">time_points</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time_points</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Obtain estimates at these points</span>
<span class="n">latent_predicted_mean</span><span class="p">,</span> <span class="n">latent_predicted_cov</span> <span class="o">=</span> \
    <span class="n">pred</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_TYPE</span><span class="p">))</span>
<span class="n">latent_predicted_mean</span><span class="p">,</span> <span class="n">latent_predicted_cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">latent_predicted_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                                               <span class="n">latent_predicted_cov</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="n">predicted_mean</span> <span class="o">=</span> <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="p">)</span>

<span class="c1"># Plot the results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span> <span class="n">predicted_mean</span><span class="p">,</span> <span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_points</span><span class="p">,</span> <span class="n">observations</span><span class="p">,</span> <span class="s1">&#39;C0x&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latent_predicted_cov</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())),</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latent_predicted_cov</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())),</span>
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_markovflow_variational_gpr_22_0.png" src="../_images/notebooks_markovflow_variational_gpr_22_0.png" />
</div>
</div>
</div>
<div class="section" id="Step-7:-Generate-sample-trajectories">
<h2>Step 7: Generate sample trajectories<a class="headerlink" href="#Step-7:-Generate-sample-trajectories" title="Permalink to this headline">Â¶</a></h2>
<p>You can also use the <code class="docutils literal notranslate"><span class="pre">vgpr.posterior.sample_f</span></code>method to generate sample trajectories.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Take 20 samples</span>
<span class="n">latent_samples</span> <span class="o">=</span> \
    <span class="n">pred</span><span class="o">.</span><span class="n">sample_f</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">future_time_points</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_TYPE</span><span class="p">),</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">latent_samples</span> <span class="o">=</span> <span class="n">latent_samples</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">Phi</span><span class="p">(</span><span class="n">latent_samples</span><span class="p">)</span>

<span class="c1"># Plot the same as previous</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_points</span><span class="p">,</span> <span class="n">observations</span><span class="p">,</span> <span class="s1">&#39;C0o&#39;</span><span class="p">)</span>

<span class="c1"># Add the samples</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">future_time_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

<span class="c1"># Add mean and confidence levels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span> <span class="n">predicted_mean</span><span class="p">,</span> <span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latent_predicted_cov</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())),</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latent_predicted_cov</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())),</span>
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_markovflow_variational_gpr_24_0.png" src="../_images/notebooks_markovflow_variational_gpr_24_0.png" />
</div>
</div>
</div>
<div class="section" id="Step-8:-Observe-more-data-in-the-future,-and-update-the-model">
<h2>Step 8: Observe more data in the future, and update the model<a class="headerlink" href="#Step-8:-Observe-more-data-in-the-future,-and-update-the-model" title="Permalink to this headline">Â¶</a></h2>
<p>You can also use <code class="docutils literal notranslate"><span class="pre">vgpc.posterior.predict_f</span></code> to get the posterior of the latent function at arbitrary time points. To demonstrate this, we will generate a set of time points that begin before the training data and extend into the future.</p>
<p>In the GPR notebook example, we could make reasonable predictions <strong>without retraining</strong> after observing a new point. We could do this because we could assume that the kernel trained on the 20 original points is probably still applicable for 21 points. In simple terms, you can think of learned kernel hyperparamters as general, high-level properties of the data (not unlike how an average value provides a high-level indication of a dataset). By reusing the hyperparamters, we are assuming that
these high-level properties havenâ€™t changed. Similarly for VGPR, it is probably reasonable to assume the kernel parameters wonâ€™t have changed materially after one extra observation, so it is not critical to retrain these.</p>
<p>Recall, however, that VGPR had a two-step training process (hyperparameters and latent approximation). Unfortunately, the latent approximations of the posterior can be very specific to the dataset they were trained on. Because of this, adding a new observation requires retraining of this approximation.</p>
<p>The following code describes how kernel hyperparameters are reused but retraining is performed on the latent approximation (phase 1, as described in Step 3).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Create a new observation and add it to the dataset</span>
<span class="n">new_time</span><span class="p">,</span> <span class="n">new_ob</span> <span class="o">=</span> <span class="n">create_binary_observations</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">33.</span><span class="p">]))</span>
<span class="n">new_time_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">time_points</span><span class="p">,</span> <span class="n">new_time</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">new_observations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">observations</span><span class="p">,</span> <span class="n">new_ob</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create a new VGP object with the previous kernel</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_time_points</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_observations</span><span class="p">))</span>
<span class="n">vgpc</span> <span class="o">=</span> <span class="n">VariationalGaussianProcess</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">Bernoulli</span><span class="p">())</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">opt_step</span><span class="p">():</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">vgpc</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">opt_step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="se">\t</span><span class="s2">Loss: </span><span class="si">{</span><span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss after optimisation: </span><span class="si">{</span><span class="n">vgpc</span><span class="o">.</span><span class="n">loss</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Obtain latent predictions</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">vgpc</span><span class="o">.</span><span class="n">posterior</span>
<span class="n">latent_predicted_mean</span><span class="p">,</span> <span class="n">latent_predicted_cov</span> <span class="o">=</span> \
    <span class="n">pred</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">FLOAT_TYPE</span><span class="p">))</span>
<span class="n">latent_predicted_mean</span><span class="p">,</span> <span class="n">latent_predicted_cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">latent_predicted_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                                               <span class="n">latent_predicted_cov</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="n">predicted_mean</span> <span class="o">=</span> <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="p">)</span>

<span class="c1"># Plot the results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span> <span class="n">predicted_mean</span><span class="p">,</span> <span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_points</span><span class="p">,</span> <span class="n">observations</span><span class="p">,</span> <span class="s1">&#39;C0x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">intermediate_time_points</span><span class="p">,</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latent_predicted_cov</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])),</span>
                 <span class="n">Phi</span><span class="p">(</span><span class="n">latent_predicted_mean</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latent_predicted_cov</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])),</span>
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_time</span><span class="p">,</span> <span class="n">new_ob</span><span class="p">,</span> <span class="s1">&#39;r*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Iteration: 0    Loss: 35.90683177528676
Iteration: 500  Loss: 12.421626540003315
Iteration: 1000 Loss: 10.447366023173851
Iteration: 1500 Loss: 9.514287561605869
Loss after optimisation: 8.964551854956564
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_markovflow_variational_gpr_26_1.png" src="../_images/notebooks_markovflow_variational_gpr_26_1.png" />
</div>
</div>
<p>When new data is available we can we see how the variance (slightly) decreases at the new point (shown by the red star).</p>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright Copyright 2021 The markovflow Contributors

Licensed under the Apache License, Version 2.0
.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>